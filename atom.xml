<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zhou-ning&#39;s Blog</title>
  
  <subtitle>毛的感情的程序猿</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-06-15T14:52:08.778Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>zhou ning</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Background Suppression Network for Weakly-supervised Temporal Action Localization</title>
    <link href="http://example.com/2021/06/15/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/Background%20Suppression%20Network/"/>
    <id>http://example.com/2021/06/15/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/Background%20Suppression%20Network/</id>
    <published>2021-06-15T22:00:00.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Background-Suppression-Network-for-Weakly-supervised-Temporal-Action-Localization"><a href="#Background-Suppression-Network-for-Weakly-supervised-Temporal-Action-Localization" class="headerlink" title="Background Suppression Network for Weakly-supervised Temporal Action Localization"></a>Background Suppression Network for Weakly-supervised Temporal Action Localization</h1><h2 id="提出问题："><a href="#提出问题：" class="headerlink" title="提出问题："></a>提出问题：</h2><p>弱监督视频动作定位中，先前的方法聚合帧级别的类分数，以产生视频级别的预测并从视频级别的动作中学习。此方法无法完全模拟问题，因为背景帧被迫错误地分类为行动类别，无法准确预测视频级标签。</p><h2 id="做了什么："><a href="#做了什么：" class="headerlink" title="做了什么："></a>做了什么：</h2><p>设计了背景抑制网络（BaSNet），该网络引入了背景的辅助类，并具有带有非对称度量训练策略的两分支权重共享体系结构。这使BaSNet可以抑制来自背景框架的激活，从而提高定位性能。广泛的实验证明了BaSNet的效率及其在最流行的基准THUMOS14和ActivityNet上优于最新方法的优越性</p><p>BaSNet：有两条分支Base branch and Suppression branch<br><span id="more"></span></p><h2 id="怎么做的："><a href="#怎么做的：" class="headerlink" title="怎么做的："></a>怎么做的：</h2><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210411104708142.png" alt="image-20210411104708142"></p><ol><li>Suppression分支包含一个过滤模块，该模块学习过滤出背景帧以最终抑制CAS中来自它们的激活</li><li>他们的培训目标是不同的。 Base分支的目的是将插入视频分类为其原始动作类和背景类的样本。另一方面，训练带有过滤模块的Suppression分支以最小化背景类得分，而背景类得分与原始动作类的目标相同。权重共享策略可以防止分支在给出相同输入时同时满足其两个目标。因此，过滤模块是解决背景的唯一关键，并且经过培训可以抑制来自背景框架的激活，从而同时实现两个目标。这减少了背景帧的干扰并提高了动作定位性能</li></ol><h3 id="特征提取："><a href="#特征提取：" class="headerlink" title="特征提取："></a>特征提取：</h3><p>由于存储器限制，我们首先将每个输入视频$v<em>n$分成16帧不重叠的$L_n$段，即$v_n = {S</em>{n,l} }^{Ln}<em>{l = 1}$。为了应对视频长度的较大变化，我们从每个视频中采样了固定数量的T段。然后，我们将采样的RGB和flow分段输入到预训练的特征提取器中，以分别生成$F$维的特征向量$x</em>{n,t}^{RGB}$和$x<em>{n,t}^{flow}$。然后，将RGB和flow特征连接起来以构建完整的特征$x</em>{n,t}$，然后将它们沿着时间维度堆叠以形成长度为T的特征图,即$X<em>n=[x</em>{n,1},…,x_{n,T}]$</p><p><strong>小结：</strong>这一步就是普通的特征提取，提取RGB和flow光流特征，然后将它们连接一下比较简单。</p><h3 id="Base-branch"><a href="#Base-branch" class="headerlink" title="Base branch"></a>Base branch</h3><p>为了预测线段级别的类别得分，我们通过将特征图馈送到时间一维卷积层中来生成CAS （类激活序列），其中每个线段都有其类别得分，反应了对应类别的概率。对于视频$v_n$，可以将其形式化如下:</p><script type="math/tex; mode=display">A_n=f_{conv}(X_n,\phi)</script><p>其中$\phi$表示卷积层中的可训练参数，$A_n\in R^{(C+1)\times T}$。一个$C+1$尺寸是因为我们使用C动作类和一个辅助类作为背景。</p><p>接着使用top-k均值技术，可以如下得出视频vn的c类的视频级类评分：</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210411151544441.png" alt="image-20210411151544441"></p><p>然后，通过沿类别维度应用softmax函数，将视频级别的类别得分用于预测每个类别的样本的概率：</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210411151640191.png" alt="image-20210411151640191"></p><p>为了训练网络，我们为每个类别定义一个具有二进制交叉熵损失的损失函数$L_{base}$</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210411151931573.png" alt="image-20210411151931573"></p><p>其中$y^{base}<em>n=[y</em>{n;1},…,y_{n;C},1]^T\in \mathbb R^{C+1}$,其中最后一个1是背景类，因为基础分支没有去除背景所以设置为1这和后面的抑制分支想对应。</p><p><strong>小结：</strong>可以知道Base branch只是简单的进行训练，默认是有背景类的。</p><h3 id="Suppression-branch"><a href="#Suppression-branch" class="headerlink" title="Suppression branch"></a>Suppression branch</h3><p>与Base分支不同，Suppression分支在其前面包含一个过滤模块，该模块被针对背景类的相反的训练目标训练为抑制背景帧。过滤模块由两个时间一维卷积层和随后的S型函数组成。过滤模块的输出是前景权重$W_n∈R^T$，范围从0到1。来自过滤模块的前景权重在时间维度上与特征图相乘以过滤出背景帧。此步骤可以表示如下：</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210411153148668.png" alt="image-20210411153148668"></p><p>接着的话和前面Base 分支的训练类似，只是将$\acute{X}_n$ 代替$X_n$</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210413103100493.png" alt="image-20210413103100493"></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210413103610515.png" alt="image-20210413103610515"></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210413103127374.png" alt="image-20210413103127374"></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210413103139512.png" alt="image-20210413103139512"></p><p>其中$y^{supp}<em>n=[y</em>{n;1},…,y_{n;C},0]^T\in \mathbb R^{C+1}$,其中最后一个1是背景类，因为基础分支没有去除背景所以设置为0，因为抑制分支经过了前面的过滤模块，默认是过滤掉背景。</p><p><strong>小结：</strong>抑制分支设置背景类为0，目的就是训练过滤模块，他们俩共享了前面的一维权重，但是最终一个有背景一个没有背景，两个分支的区别就在于过滤模块，这也是所谓的非对称共享权重训练。</p><h3 id="Joint-training"><a href="#Joint-training" class="headerlink" title="Joint training"></a>Joint training</h3><p>我们联合训练base分支和Suppression 分支。我们需要优化的总体损失函数如下：</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Background Suppression Network for Weakly-supervised Temporal Action Localization/image-20210411154052601.png" alt="image-20210411154052601"></p><p>前两个在上面已经介绍了，而$L_{norm}$:</p><script type="math/tex; mode=display">L_{norm}=\frac{1}{N}\sum_{n=1}^N|w_n|</script><p>这个其实对训练的过滤模块权重进行$L_1$正则，目的是使得权重更加偏向0或者1，简单理解就是背景帧就是0进行抑制，动作帧就是1不受影响。术语就是更好的识别关键帧</p><p><strong>小结：</strong>这个$L_{norm}$的设计还是比较巧妙，可能也是我接触比较少</p><h3 id="Classification-and-Localization"><a href="#Classification-and-Localization" class="headerlink" title="Classification and Localization"></a>Classification and Localization</h3><p>在描述了我们的模型是如何配置和训练的之后，我们转向讨论它在测试时如何工作。由于我们使用过滤模块阻止来自背景框架的激活，因此使用Suppression分支的输出进行推理是合理的。对于分类，我们丢弃在概率低于阈值$\theta<em>{class}$的类。然后，对于其余类别，我们使用阈值$\theta</em>{act}$对CAS进行阈值选择候选片段。然后，每组连续的候选段将成为一个建议。我们根据最近的工作，使用内部和外部区域之间的对比来计算每个建议的置信度得分。</p><p><strong>小结：</strong>这个分类和定位比较平常 ，不多介绍</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>这篇<code>Background Suppression Network for Weakly-supervised Temporal Action Localization</code>还真的在设计上就十分巧妙，两个分支一个训练有背景，一个训练却没有背景，两个分支的不同之处就只有过滤模块，所以说明了过滤模块的作用。最终的话使用过滤分支输出的概率和CAS来进行定位也是比较合理。</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Background-Suppression-Network-for-Weakly-supervised-Temporal-Action-Localization&quot;&gt;&lt;a href=&quot;#Background-Suppression-Network-for-Weakly-supervised-Temporal-Action-Localization&quot; class=&quot;headerlink&quot; title=&quot;Background Suppression Network for Weakly-supervised Temporal Action Localization&quot;&gt;&lt;/a&gt;Background Suppression Network for Weakly-supervised Temporal Action Localization&lt;/h1&gt;&lt;h2 id=&quot;提出问题：&quot;&gt;&lt;a href=&quot;#提出问题：&quot; class=&quot;headerlink&quot; title=&quot;提出问题：&quot;&gt;&lt;/a&gt;提出问题：&lt;/h2&gt;&lt;p&gt;弱监督视频动作定位中，先前的方法聚合帧级别的类分数，以产生视频级别的预测并从视频级别的动作中学习。此方法无法完全模拟问题，因为背景帧被迫错误地分类为行动类别，无法准确预测视频级标签。&lt;/p&gt;
&lt;h2 id=&quot;做了什么：&quot;&gt;&lt;a href=&quot;#做了什么：&quot; class=&quot;headerlink&quot; title=&quot;做了什么：&quot;&gt;&lt;/a&gt;做了什么：&lt;/h2&gt;&lt;p&gt;设计了背景抑制网络（BaSNet），该网络引入了背景的辅助类，并具有带有非对称度量训练策略的两分支权重共享体系结构。这使BaSNet可以抑制来自背景框架的激活，从而提高定位性能。广泛的实验证明了BaSNet的效率及其在最流行的基准THUMOS14和ActivityNet上优于最新方法的优越性&lt;/p&gt;
&lt;p&gt;BaSNet：有两条分支Base branch and Suppression branch&lt;br&gt;</summary>
    
    
    
    <category term="论文学习" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="时间动作定位" scheme="http://example.com/tags/%E6%97%B6%E9%97%B4%E5%8A%A8%E4%BD%9C%E5%AE%9A%E4%BD%8D/"/>
    
    <category term="时序动作定位" scheme="http://example.com/tags/%E6%97%B6%E5%BA%8F%E5%8A%A8%E4%BD%9C%E5%AE%9A%E4%BD%8D/"/>
    
    <category term="动作检测" scheme="http://example.com/tags/%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>Learning Temporal Co-Attention Models for Unsupervised Video Action Localization</title>
    <link href="http://example.com/2021/06/15/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/Learning%20Temporal%20Co-Attention%20Models%20for%20Unsupervised%20Video%20Action/"/>
    <id>http://example.com/2021/06/15/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/Learning%20Temporal%20Co-Attention%20Models%20for%20Unsupervised%20Video%20Action/</id>
    <published>2021-06-15T22:00:00.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Learning-Temporal-Co-Attention-Models-for-Unsupervised-Video-Action-Localization"><a href="#Learning-Temporal-Co-Attention-Models-for-Unsupervised-Video-Action-Localization" class="headerlink" title="Learning Temporal Co-Attention Models for Unsupervised Video Action Localization"></a>Learning Temporal Co-Attention Models for Unsupervised Video Action Localization</h1><h2 id="提出问题"><a href="#提出问题" class="headerlink" title="提出问题"></a>提出问题</h2><p>未修剪视频中的时间动作定位（Temporal action localization，TAL） 最近获得了巨大的研究热情，但是TAL目前并没有无监督的的方法出现，所以本论文提出了第一种无监督的TAL方法。</p><h2 id="做了什么"><a href="#做了什么" class="headerlink" title="做了什么"></a>做了什么</h2><p>为了解决动作定位，两步进行 “聚类+定位”迭代过程。</p><p>聚类步骤为定位步骤提供了noisy的伪标记，而定位步骤提供了时间共关注模型，从而提高了聚类性能，这两个过程相辅相成。</p><p>在弱监督下 TAL可被视为我们ACL的直接扩展模型。</p><p>从技术上讲，我们的贡献有两个方面：</p><ul><li><p>从视频级标签或伪标签中学习的时间共同注意模型，无论是针对特定类别还是不可知类别的 以反复强化的方式； </p></li><li><p>为ACL设计了新的loss，包括<code>action-background separation loss</code>和<code>cluster-based triplet loss</code>。 </p></li></ul><p>最终的成绩：</p><p>针对20种动作THUMOS14和100种 行动ActivityNet-1.2。 在两个基准上，建议 ACL的模型具有强大的性能，甚至可以与最新的弱监督方法相比。 例如，以前最好的弱监督 在THUMOS14上的mAP@0.5下，模型达到了26.8％， 我们的新记录分别为30.1％（弱监督）和25.0％ （无监督）。</p><span id="more"></span><h2 id="怎么做"><a href="#怎么做" class="headerlink" title="怎么做"></a>怎么做</h2><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415103823407.png" alt="image-20210415103823407"></p><h3 id="Video-Feature-Extraction"><a href="#Video-Feature-Extraction" class="headerlink" title="Video Feature Extraction"></a>Video Feature Extraction</h3><p>给定一个未修剪的视频，我 令$X^R,X^F\in \mathbb{R}^{T \times D}$分别代表片段式RGB和flow特征序列，其中$T$代表片段的数量，$D$代表特征尺寸。</p><h3 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h3><p>目前我们知道训练集的动作类别<code>C</code>的数量。为了获得每个视频的视频级伪标签，我们在训练集上利用频谱聚类算法来获得<code>C</code>个聚类，以便可以根据视频的分配给每个视频一个伪标签。</p><p>对于每个视频$v$,我们同样得到视频的RGB和flow特征$X^R,X^F\in \mathbb{R}^{T \times D}$，令$S^R<em>{v,i},S^F</em>{v,i} \in R ^{T_v×1}$为第i次迭代中的class-agnostic attention weights权重。因为这个是训练的时候才能得到所以最开始可以都设为<code>1/T</code></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action//image-20210415160529774.png" alt="image-20210415160529774"></p><p>对于视频$v$在迭代i产生的RGB特征和光流特征就能得到</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415161152468.png" alt="image-20210415161152468"></p><p>将每个视频$v$的RGB特征$f^R$和光流特征$f^F$  concatenate成最后的总特征$f_i$（这个目的是去除掉背景），这样就得到了每个视频$v$的特征，就可以构建图结构了。</p><p>对于图G = {V, E}，其中V表示顶点的集合，即训练集视频，E表示边缘的集合。其中$v<em>i,v_j$的权重$w</em>{i,j}$由</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415161728852.png" alt="image-20210415161728852"></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415161738706.png" alt="image-20210415161738706"></p><p>计算得来。基于构造的图，使用频谱聚类算法将未修剪的视频分组为C个簇，每个簇都定义了一个伪动作。然后，将这些视频级伪标签用于训练动作定位模型。对于弱监督扩展，每个视频均具有视频级别标签，因此跳过了聚类。</p><h3 id="Local-Global-Feature-Aggregation-Block"><a href="#Local-Global-Feature-Aggregation-Block" class="headerlink" title="Local-Global Feature Aggregation Block"></a>Local-Global Feature Aggregation Block</h3><p>由于每个段的特征仅包含当前代码段的信息，因此缺少时间上下文信息。为了提高每个代码段特征的可分辨性，提出了局部全局特征聚合块（Local-Global Feature Aggregation Block，FAB）以提取局部和全局上下文信息</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415162119941.png" alt="image-20210415162119941"></p><p>FAB主要是三个部分：</p><ul><li>a 1D temporal convolution branch</li><li>a dilated temporal pyramid branch</li><li>a global context branch</li></ul><p>dilated temporal pyramid branch由2个并行的卷积组成，它们具有不同的扩张率，以聚集局部时间上下文。</p><p>global context branch使用non-local网络捕获所有帧之间的时间相关性。在全局上下文分支之前添加了内核大小为1的一维时间卷积以降低计算成本。</p><p>所有分支的输出通过一维时间卷积进行级联和融合。这步可以理解为将特征富含上了上下文信息，即视频的时序信息，经过了这个module后便得到了特征信息$X_e$</p><h3 id="Class-Specific-Temporal-Attention-Module"><a href="#Class-Specific-Temporal-Attention-Module" class="headerlink" title="Class-Specific Temporal Attention Module"></a>Class-Specific Temporal Attention Module</h3><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415173239749.png" alt="image-20210415173239749"></p><p>这个模块的功能主要是获得在不同时间出现的不同动作类别的概率。</p><p>以$X_{cs}$中间层作为输入，输出类特定分数$A \in R^{T \times C}$,其中T是分段数，C是分类总数，这里可以理解为分数A表示了每段是某一类动作的概率。最终还是加上了softmax来归一化</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415172547677.png" alt="image-20210415172547677"></p><p>这个模块除了计算分数A之外，还会计算动作背景分离损失(action-background separation loss)。</p><p>对于一批训练视频，我们从随机训练集的$C$簇中，抽取出$Z$簇，再从$Z$簇中各自抽取出$K$个视频，定义$V_z$为属于某以簇的$K$个视频的集合</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415193402240.png" alt="image-20210415193402240"></p><p>对于每个视频$v_k$，我们计算动作特征和背景特征</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415193715643.png" alt="image-20210415193715643"></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415193703592.png" alt="image-20210415193703592"></p><p>除此之外还要加上这三条限制：</p><p>假设我们有一对属于$V_z$的视频$v_m$和$v_n$。令d表示余弦距离函数，τ1和τ2分别表示两个cos余弦距离。</p><p>为了确保视频间动作的高度相似性，我们使用以下等式来强制执行此要求:</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415194047630.png" alt="image-20210415194047630"></p><p>为了满足较高的视频内动作-背景清晰度，我们使用以下方程式:</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415194318008.png" alt="image-20210415194318008"></p><p>然后我们就可以得到损失函数</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415194718815.png" alt="image-20210415194718815"></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415194728168.png" alt="image-20210415194728168"></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415194739349.png" alt="image-20210415194739349"></p><p>这个loss的作用主要是加强同簇中视频的动作相似性和动作背景的分离性</p><h3 id="Class-Agnostic-Temporal-Attention-Module"><a href="#Class-Agnostic-Temporal-Attention-Module" class="headerlink" title="Class-Agnostic Temporal Attention Module"></a>Class-Agnostic Temporal Attention Module</h3><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415173213102.png" alt="image-20210415173213102"></p><p>这个模块的功能是为了学习和动作类别无关的部分即背景部分出现的概率</p><p>以$X_{ca}$作为输入，输出类无关分数$S \in R^{T \times 1}$，这个分数和上面的$A$有相同的作用</p><p>除了计算$S$之外，这个模块也计算了cluster-based triplet loss，计算方式和上面有些类似</p><p>先计算class-agnostic video feature representation H</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415195736514.png" alt="image-20210415195736514"></p><p>抽取出某一簇内的一个视频$v_a$，假设$v_n$是不在群集z中并且与$v_a$的距离最小的视频，$v_p$是群集z中的视频并且与$v_a$的距离最大，有这样的限制：</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415200547254.png" alt="image-20210415200547254"></p><p>接着就可以计算cluster-based triplet loss</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415200747883.png" alt="image-20210415200747883"></p><p>这个LOSS的意义很明确，为了将同一聚类的视频特征表示拉近，并将不同聚类的视频特征表示在特征空间中推得更远</p><h3 id="最终loss计算"><a href="#最终loss计算" class="headerlink" title="最终loss计算"></a>最终loss计算</h3><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415202421538.png" alt="image-20210415202421538"></p><p>其中$L_{cls}$是经典的交叉熵损失</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/image-20210415202705033.png" alt="image-20210415202705033"></p><p>其中$y_n$表示视频$v_n$的标签，${p}^n$表示视频$v_n$的预测标签。</p><p>至于$p$的是计算方法则是<br><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/Learning Temporal Co-Attention Models for Unsupervised Video Action/202009101218470.png" alt="在这里插入图片描述"></p><p>通过沿p上的类别维执行softmax，可以得到动作类$\hat {p}^n$上的概率分布</p><p>参考：<a href="https://blog.csdn.net/qq_43310834/article/details/108502214">https://blog.csdn.net/qq_43310834/article/details/108502214</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Learning-Temporal-Co-Attention-Models-for-Unsupervised-Video-Action-Localization&quot;&gt;&lt;a href=&quot;#Learning-Temporal-Co-Attention-Models-for-Unsupervised-Video-Action-Localization&quot; class=&quot;headerlink&quot; title=&quot;Learning Temporal Co-Attention Models for Unsupervised Video Action Localization&quot;&gt;&lt;/a&gt;Learning Temporal Co-Attention Models for Unsupervised Video Action Localization&lt;/h1&gt;&lt;h2 id=&quot;提出问题&quot;&gt;&lt;a href=&quot;#提出问题&quot; class=&quot;headerlink&quot; title=&quot;提出问题&quot;&gt;&lt;/a&gt;提出问题&lt;/h2&gt;&lt;p&gt;未修剪视频中的时间动作定位（Temporal action localization，TAL） 最近获得了巨大的研究热情，但是TAL目前并没有无监督的的方法出现，所以本论文提出了第一种无监督的TAL方法。&lt;/p&gt;
&lt;h2 id=&quot;做了什么&quot;&gt;&lt;a href=&quot;#做了什么&quot; class=&quot;headerlink&quot; title=&quot;做了什么&quot;&gt;&lt;/a&gt;做了什么&lt;/h2&gt;&lt;p&gt;为了解决动作定位，两步进行 “聚类+定位”迭代过程。&lt;/p&gt;
&lt;p&gt;聚类步骤为定位步骤提供了noisy的伪标记，而定位步骤提供了时间共关注模型，从而提高了聚类性能，这两个过程相辅相成。&lt;/p&gt;
&lt;p&gt;在弱监督下 TAL可被视为我们ACL的直接扩展模型。&lt;/p&gt;
&lt;p&gt;从技术上讲，我们的贡献有两个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;从视频级标签或伪标签中学习的时间共同注意模型，无论是针对特定类别还是不可知类别的 以反复强化的方式； &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;为ACL设计了新的loss，包括&lt;code&gt;action-background separation loss&lt;/code&gt;和&lt;code&gt;cluster-based triplet loss&lt;/code&gt;。 &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最终的成绩：&lt;/p&gt;
&lt;p&gt;针对20种动作THUMOS14和100种 行动ActivityNet-1.2。 在两个基准上，建议 ACL的模型具有强大的性能，甚至可以与最新的弱监督方法相比。 例如，以前最好的弱监督 在THUMOS14上的mAP@0.5下，模型达到了26.8％， 我们的新记录分别为30.1％（弱监督）和25.0％ （无监督）。&lt;/p&gt;</summary>
    
    
    
    <category term="论文学习" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="时间动作定位" scheme="http://example.com/tags/%E6%97%B6%E9%97%B4%E5%8A%A8%E4%BD%9C%E5%AE%9A%E4%BD%8D/"/>
    
    <category term="时序动作定位" scheme="http://example.com/tags/%E6%97%B6%E5%BA%8F%E5%8A%A8%E4%BD%9C%E5%AE%9A%E4%BD%8D/"/>
    
    <category term="动作检测" scheme="http://example.com/tags/%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>A Survey on Temporal Action Localization</title>
    <link href="http://example.com/2021/06/15/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/A%20Survey%20on%20Temporal%20Action%20Localization/"/>
    <id>http://example.com/2021/06/15/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/A%20Survey%20on%20Temporal%20Action%20Localization/</id>
    <published>2021-06-15T22:00:00.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<p>[toc]</p><h1 id="A-Survey-on-Temporal-Action-Localization"><a href="#A-Survey-on-Temporal-Action-Localization" class="headerlink" title="A Survey on Temporal Action Localization"></a>A Survey on Temporal Action Localization</h1><blockquote><p><strong>摘要:</strong>在计算机视觉中，时间动作定位是视频理解中最关键也是最具挑战性的问题之一。由于其广泛的应用，近年来引起了广泛的关注日常生活应用。时间动作定位技术已经取得了很大的进展，特别是最近深度学习的发展。而且在未裁剪的情况下，现在需要更多的时间动作定位视频。在这篇论文中，我们的目标是调查最新的技术和模型的视频时间行动定位。主要包括相关技术、一些基准数据集和评价时间动作定位的度量。此外，我们从两个方面总结了时间动作定位各方面:全监督学习和弱监督学习。并列举了几部具有代表性的作品并比较他们各自的表现。最后，对其进行了深入分析，并提出了发展前景研究方向，并总结调查。</p></blockquote><p><strong>关键词</strong>：动作检测，计算机视觉，全监督学习，时间动作定位，弱监督学习。</p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1.引言"></a>1.引言</h2><p>随着视频数量急剧的增长，视频理解成为了计算机视觉领域的一个热点问题和具有挑战性的方向。这个视频理解发个信包括许多子研究方向，包括在夏威夷，被CVPR举办的ActivityNet 挑战2017，这个网络一共提出了5个任务。</p><ul><li>未裁剪的视频分类(Untrimmed Video Classification )</li><li>裁剪后的行动识别( Trimmed Action Recognition)</li><li>时间动作检测( Temporal Action Proposals)</li><li>时间动作定位(Temporal Action Localization)</li><li>视频中密集的字幕事件(Dense-Captioning Events in Videos)</li></ul><p>在最近的调查中，我们关注的是时间动作定位，也就是上面列出的第四个。它需要检测包含目标动作的时间间隔。对于长时间的<strong>未裁剪的视频</strong>，时间动作定位主要解决两个任务，识别和定位。特别是,a)动作发生的起始时间和终止时间,b)每个提案的类别是什么属于(如挥手、爬山、扣篮)。当然，一个视频可能包含一个或多个行动剪辑(action clips),所以时间动作定位是要开发模型和技术来提供计算机视觉应用所需要的最基本的信息:动作是什么，动作什么时候发生?我们将这个任务作为动作定位，或时间动作定位，或动作检测。</p><p>虽然动作识别和动作本地化都是视频理解里面很重要的任务，但是时间动作定位比动作识别更加具有挑战性。动作识别和动作定位的关系和图像检测类似于图像识别和图像检测。但是由于时间连续信息(temporal series information),时间动作定位比图像检测更见困难。困难主要来自以下几个方面：<strong>a)</strong>时间信息，由于1维时间连续信息，时间动作定位不能使用静态图片信息，它必须结合时间连续信息。<strong>b)</strong>与目标检测不同的是，边界对象通常是非常清晰的，所以我们可以为对象标记一个更清晰的边界框。然而，可能没有关于动作的确切时间范围合理定义，所以，不可能给一个动作开始和结束的准确边界。<strong>c)</strong>大的时间跨度，时间动作片段的跨度可以是非常大的，比如，挥手可能只几秒钟但是攀岩和骑自行车能够持续十几秒。它们时间跨度在长度上的不同，是的提取检测(extract proposals)很困难。另外，在开放的环境当中，这里也又许多问题，例如多尺度，多目标和相机移动。</p><p>时间动作定位非常贴近我们的生活，它具有广泛的应用前景和社会价值在视频概况(video summarization)、公共视频监控、技能评估和日常生活安全。所以它在最最近几年得到了广泛的关注。与“动作检测”有关的出版物总数约为324127份，近二十年来包括书籍、期刊、论文、会议论文、专利和一些科技成果。下面我们主要分析出版学术和回忆论文的趋势动作检测，如同<strong>图1</strong>所示</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/image-20201027193624091.png" alt=""></p><p>本调查旨在帮助对时态动作本地化感兴趣的初学者。它提供一个概括动作定位的方法和最新进展，本文余下部分组织如下。</p><ul><li>第二节概述相关技术。</li><li>第三节介绍基本的时间动作定位数据集</li><li>第四节描述模型的性能评估指标</li><li>第五节从全监督和弱监督两方面，提供一个时间动作定位模型和方法的概述</li><li>第六节讨论现在的挑战和建议未来的方向</li><li>第七节总结本论文</li></ul><span id="more"></span><h2 id="2-相关技术"><a href="#2-相关技术" class="headerlink" title="2.相关技术"></a>2.相关技术</h2><p>因为最近时间本地化已经成为了一个活跃的研究领域，许多解决此问题的不同的方法被提出。虽然动作检测已经研究了许多年，但是它仍处于实验室数据集的测试阶段，没有实际的实用性和工业化。理解视频中动作发生的时间和内容是非常具有挑战性的。可以看出，目前对于这个任务仍然没有健壮的解决方案。在本节中，我们将回顾时间动作定位的相关技术。</p><p>众所周知，视频特征表示可以为视频动作提供有用的信息，并且很多实验已经被做了。在过去的二十年，众所周知特征提取的进展一般经历了两个重要的历史时期。一个是传统的动作检测阶段在2014年之前，另一个时期时深度学习阶段，在2014年之后。时间线框架如<strong>图2</strong>所示</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/image-20201027201856154.png" alt="image-20201027201856154"></p><p>在深度学习阶段，它们主要被分为两种类型框架：“两阶段检测(‘two-stage detection)”和“一阶段检测（one-stage detection）”。特别，前面一种依赖“检测和分类”(proposal-then-classification)范式，这是一个主流方法，后一种同时检测和分类,所以我们称之为一级检测</p><h3 id="A-传统的方法-TRADITIONAL-METHODS"><a href="#A-传统的方法-TRADITIONAL-METHODS" class="headerlink" title="A.传统的方法(TRADITIONAL METHODS)"></a>A.传统的方法(TRADITIONAL METHODS)</h3><p>由于动作识别是时间动作定位的一部分，所以大多数早期动作定位算法都依赖于手动制作的特点，这一点和动作识别相同。这里有几种方式去提取视频特征，包含静态图像特征和时间视觉特征。具体来说，静态图像特征是SIFT (ScaleInvariant Feature Transform，特性变换)和 HOG (Histogram of Oriented Gradients，倾斜的直方图)等待。HOG可以认为是SIFT的一种改进，然而时间视觉特征是静态图像信息和时间信息的结合。通过这些特征，可以得到视频的时间信息。</p><p>一般来说，我们能够将特征提取分为局部特征提取和全局特征提取。<strong>a)</strong>局部特征提取是指视频中的局部感兴趣点和感兴趣区域，包括统计数据，字段学习(dictionary learning),bagof-words (BoW),特征学习等等。和全局特征提取想比较，局部特征提取对于视频照明、投是、相机抖动和复杂背景更具有健壮性。<strong>b)</strong>全局特征提取指的是人类行为的整体特征，如人体的轮廓、骨架等，它包括全局密度和轨迹方法。为了解决在复炸场景中人类行为的问题，仅仅检测时空区域灰度变化是不够的。因此，研究人员已经提出了许多依赖于点轨迹的特征提取的方法。近似的过程如下：第一，这些方法先在视频的时间区域检测特征点，然后一帧一帧跟踪这些特征点，并将形成的特征点的轨迹连接起来，最后它们使用特征描述器(feature descriptors)来描述这个轨迹和它的时间域。许多特征提取的方法依赖特征点的轨迹传统方法是Dense Trajectories (DT)，随后，考虑到摄像机的运动导致DT提取的特征和人类行为不相关关联，DT特征提取被更深的改进了，一种叫iDT的方法被提出。iDT的非常有价值的见解(valuable insight)仍然影响着以后的研究工作。值得注意的是深度学习和iDT的结合通常可以更进一步的提高性能。许多论文已经采纳以”我们的方法+iDT”的形式去实现最高水平SOTA(state-of-the-Art)</p><p>  无论如何，传统特征提取方法的研究过程和思想非常有用，因为这些方法具有很强的可解释性。它们为设计深度学习方法来解决此类问题提供了启发和类比。</p><h3 id="B-深度学习的方法-DEEP-LEARNING-METHODS"><a href="#B-深度学习的方法-DEEP-LEARNING-METHODS" class="headerlink" title="B.深度学习的方法(DEEP LEARNING METHODS)"></a>B.深度学习的方法(DEEP LEARNING METHODS)</h3><p>随着使用手工特征提取的方法的表现变得稳定，时间动作定位以及达到了一定高度。随着卷积神经网络的重生，大量的研究也随之兴起。卷积神经网络可以学习见状的和高水准的特征表示。比如，一个2D-CNN对于一个大规模的视频分类是李菲菲的小组在年提出来的。虽然它的表现和依赖传统方法的特征提取不能相比，但是这个想法启发了后来的研究人员。后来，两种流派CNN((RGB frames and optical flow),  3D卷积神经网络和紧接着它们的变化成为了学习动作识别中的区别性特征受欢迎方法。随后，一个结合两种流派和C3D网络被命名为I3D(Inception 3D)被提出。而且它以及成为了一种通用的视频特征表示编码器(video feature representation encoder)。除了几种依赖神经网络的方法被介绍用来捕捉动态的动作识别，TSN通过稀疏采样的策略，也被设计来对整个视频信息进行平均聚集建模。根据<strong>图1</strong>，我们值得，深度学习分为两种类型：两阶段定位和一阶段定位。</p><h4 id="1）两阶段定位方法"><a href="#1）两阶段定位方法" class="headerlink" title="1）两阶段定位方法"></a>1）两阶段定位方法</h4><p>两阶段类型依赖定位-然后-分类( proposal-thenclassification)的范式.这个范式先提取时间定位，然后接着处理分类和回归操作。这方式是主流方法，所以大多数论文都是采用此方法。事实上，这个定位的生成是时间定位范式中的一个难点，这个和目标检测中定位的生成相类似(RNN中区域定位生成)。一个好的定位算法可以更好的提高这个模型的效果</p><p>时间动作定位生成器的任务是生成一定数量的时间定位对于一个未裁剪的长视频。一个时间动作定位是一个时间间隔包含动作片段(从起点边界到终点边界)。一般来说，平均召回率用来衡量算法的性能。数据库一般使用ActivityNet和THUMOS14，有几种方法提取定位的方法。</p><h5 id="a-滑动窗口-SLIDING-WINDOW-S-CNN-14-2016"><a href="#a-滑动窗口-SLIDING-WINDOW-S-CNN-14-2016" class="headerlink" title="a:滑动窗口(SLIDING WINDOW,S-CNN [14], 2016)"></a>a:滑动窗口(SLIDING WINDOW,S-CNN [14], 2016)</h5><p>在2016年，S-CNN第一个方法是固定一些大小滑动窗口去生成各种大小不同的视频片段，然后通过多级网络(SegmentCNN)处理这些片段。SCNN包括3个子网络都使用C3D网络。第一个是定位(proposal)网络，它用来确定当前路段是一个动作的概率，第二个是分类网络，用来给视频片段分类，第三个是定位(localization)网络,它的输出任然是一个类别的概率。并在训练过程中加入重叠相关的损失函数，使得网络能够更好地估计视频片段的类别喝重叠。原则上，当重叠度越高，效果越好。最后non-maximized suppression (NMS)被用于重复的片段和完成预测。</p><p>理论上，只有重叠足够高，这种方法是最全面的，但它有更多的冗余。</p><h5 id="b-时间活动分组-TEMPORAL-ACTIONNESS-GROUPING-TAG-15-2017"><a href="#b-时间活动分组-TEMPORAL-ACTIONNESS-GROUPING-TAG-15-2017" class="headerlink" title="b:时间活动分组(TEMPORAL ACTIONNESS GROUPING,TAG [15], 2017)"></a>b:时间活动分组(TEMPORAL ACTIONNESS GROUPING,TAG [15], 2017)</h5><p>以前的工作使用滑动窗口去提取建议的区域，但是这个方法不能处理不同视频动作长度。因为一般的是动作识别，卷积适用于密集视频帧，而且对于长动作视频滑动窗口消耗的资源太多。</p><p>Y. Xiong et al在2017年提出了一个新的框架用来准确的确定不同长度的动作视频的边界。这个框架包含两个部分：生成时间区域(generating temporal proposals)和分类待选(classifying proposed candidates)。前一部分生成一系列的建议区域，而后者确定它是否是一个动作并且预测它的类别。未来生成时间建议区域，TAG网络被提出。他们有三个主要步骤：a)提取片段(Extract snippets):每个片段包含一个视频的帧和视觉留信息，而且片段是在一个规律的间隔内获得的。b)动作：判断一个片段是否包含动作，为了做这件事，它使用TSN(Temporal Segment Network)学习二分类网络。c)分组：对于输出的片段序列和他们的概率，它将那些得分较高的连续片段进行分组。与此同时，设置一些阈值去删除分数较低的片段，以防止噪声干扰，并且通常设置多组阈值，以防止缺失建议区域。</p><p>这个方法对于边界更加灵活，但是它可能因为分类错误而错过一些建议区域</p><h5 id="c-时间单位回归网络-TEMPORAL-UNIT-REGRESS-NETWORK-TURN-TAP-16-2017"><a href="#c-时间单位回归网络-TEMPORAL-UNIT-REGRESS-NETWORK-TURN-TAP-16-2017" class="headerlink" title="c:时间单位回归网络(TEMPORAL UNIT REGRESS NETWORK,TURN TAP [16], 2017)"></a>c:时间单位回归网络(TEMPORAL UNIT REGRESS NETWORK,TURN TAP [16], 2017)</h5><p>在SCNN网络中，它使用滑动窗口去寻找建议区域。如果你想得到准确的结果，你需要增加窗口之间的额重叠，这回导致计算量大的问题。</p><p>为了减少计算量和增加时间定位准确度，在2017， Gao J.Y. et al在faster-RCNN映入边界回归方法的基础上，提出了转向学习的方法。这个方法将视频分割成固定大小的单元，列入16帧的单元，然后将每个单元放入C3D种提取水平特征。相邻单元形成一个clip，让么个单位形成一个锚单位，构成一个clip金字塔。然后在单元处进行时间坐标回归，这个网络包含两个输出，第一个输出是确定clip是否包含动作的分数；第二个输出是调整边界的时间坐标偏移量。</p><p>这个方法主要的贡献如下：1）一种利用坐标回归生成时间建议分段的新方法。2）快的速度(800fps)。3）一个新的评价指标AR-F被提出</p><h5 id="d-边界敏感网络-BOUNDARY-SENSITIVE-NETWORK-BSN-21-2018"><a href="#d-边界敏感网络-BOUNDARY-SENSITIVE-NETWORK-BSN-21-2018" class="headerlink" title="d:边界敏感网络(BOUNDARY SENSITIVE NETWORK ,BSN [21], 2018)"></a>d:边界敏感网络(BOUNDARY SENSITIVE NETWORK ,BSN [21], 2018)</h5><p>众所周知，高质量的时间动作建议区域应该有一下几点特征：a)灵活的时间长度,b)精确的时间界限,c)可靠的信心得分。但是现有的方法不能同时兼顾这些方面，为了解决这些困难，T. Lin et al. [21]提出了BSN在2018年。</p><p>简略的说，BSN搜先定位时间动作片段的边界(开始节点和结束节点)。边界节点直接组合成一个时间建议区域。然后根据每个建议区域提案的动作置信度评分序列提取一个32维建议区域特征。最后，根据所提取的建议区域层次特征，对时间提案的置信度进行评估。</p><p>这方法主要的贡献如下：a)新颖的框架可以在同一时间满足上诉三点。b)BSN模块简单灵活，缺点是:a)对每个时间方案逐个进行特征提取和置信度评估，效率不够。b)语义信息不足。为了保证动作建议区域特征提取的效率，BSN设计的32维特征相对简单，但也限制了置信度评价模块获取更多的语义信息。c)该方法具有多阶段性。它没有联合优化网络的几个部分。</p><h5 id="e-边界匹配网络-BOUNDARY-MATCHING-NETWORK-BMN-72-2019"><a href="#e-边界匹配网络-BOUNDARY-MATCHING-NETWORK-BMN-72-2019" class="headerlink" title="e:边界匹配网络(BOUNDARY-MATCHING NETWORK,BMN [72], 2019)"></a>e:边界匹配网络(BOUNDARY-MATCHING NETWORK,BMN [72], 2019)</h5><p>为了解决BSN的缺点，新的时间建议区域置信度评价机制喝边界匹配机制也由T. Lin在2019年提出。BMN能够生成一维边界概率喝二维BM置信度图。然后对所有可能的时间建议区域进行密集评估。</p><p>以上时间动作建议区域方法的性能比较如表1所示。</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/image-20201114104053741.png" alt=""></p><h4 id="一阶段定位方法"><a href="#一阶段定位方法" class="headerlink" title="一阶段定位方法"></a>一阶段定位方法</h4><p>另一种是同时处理建议区域和分类的一阶段框架。比如，在2017年T. Lin 提出SSAD和李菲菲提出了SS—TAD（端到端，单流时间动作检测）。他们都是基于单个检测器。由于时间动作定位和目标检测相似性，SSAD结合了YOLO和SSD两种目标检测模型的特点。SSAD的一般流程如下，使用提前训练的模型，得到特征序列，作为SSAD模型的输入。模型处理后输出检测结果。而SS-TAD将时间动作定位的语义子任务作为调整语义约束，提高了训练和测试性能。效果优于SSAD，SS-TAD提取特征使用C3D，与SSAD相同。而SS-TAD采用锚定机构和叠加GRU单元。最近，Fuchen Long介绍了GTAN(Gaussian Temporal Awareness Networks,高斯时间感知网络),该网络将时间结构与单阶段动作定位相结合。在GTAN，该算法引入高斯核函数，动态优化每个动作建议的时间尺度。</p><p>此外，有些方法基于顺序决策过程，也属于单阶段框架。例如，文献10是第一个提出在视频中学习动作检测的端到端的方法。在这篇文章中,它使用强化学习来训练一个基于rnn的代理。代理可以不断观察视频帧，并决定下一步看哪里，何时生成动作预测</p><h2 id="3-基准数据集"><a href="#3-基准数据集" class="headerlink" title="3.基准数据集"></a>3.基准数据集</h2><p>虽然没有一个时间动作定位的标准基准，但大多数研究人员使用THUMOS14[6]和ActivityNet [7]。此外，还有几个大型数据集用于时间动作检测。比如，MEXaction2、MutiTHUMOS、Charades和AVA等。下面这段主要介绍几种常用的数据集</p><h3 id="A-THUMOS14"><a href="#A-THUMOS14" class="headerlink" title="A.THUMOS14"></a>A.THUMOS14</h3><p>THUMOS14来自2014年的THUMOS Challenge。这个数据集包含两个任务：动作识别和时间动作检测。大多数论文都在这个数据集中进行评估。THUMOS数据集在其训练、验证和测试集中有101个动作类的视频级注释，而在20个类的验证和测试集中只有一小部分视频有时态注释。</p><p>一些全监督学习方法的细节如下:a)训练集:UCF101,101种动作类型，共计修剪了13320个视频剪辑。b)验证集：1010个未修剪的视频，其中200个贴有时间注释。(3007个动作片段，只有20个类可以用于时间动作检测任务)。c)测试集：1574个未修剪的视频，其中213个有时态动作注释。（3358个行为片段，只有20个类可以用于时间动作检测任务）</p><p>总之，这个数据集很有挑战性，因为有些视频比较长(长达26分钟)，并且包含多个动作实例。动作的长度在一秒到几分钟之间变化很大。</p><h3 id="B-ActivityNet"><a href="#B-ActivityNet" class="headerlink" title="B.ActivityNet"></a>B.ActivityNet</h3><p>ActivityNet数据集是最近引入动作识别和动作定位基准的最大的非裁剪视频数据集。该数据集只提供YouTube视频链接，不能直接下载视频。所以我们需要使用YouTube下载工具自动下载。ActivityNet1.3包含10,024个训练视频，4,926个验证视频，5044个测试视频，200个活动类别，如“遛狗”、“跳远”和“给地板吸尘”。ActivityNet1.3 平均每个视频只包含1.5次出现，大多数视频只包含单个动作类别，平均36%的背景。</p><p>这个数据集包含在语义分类下涉及各种人类活动的大量自然视频。</p><h3 id="C-MEXaction2"><a href="#C-MEXaction2" class="headerlink" title="C.MEXaction2"></a>C.MEXaction2</h3><p>MEXaction2数据集包含两种类型的动作，即骑马和斗牛。这个数据集由三部分组成:YouTube视频，UCF101中的骑马视频和INA视频。其中UCF101中的YouTube视频片段和骑马视频是裁剪后的短视频片段，用于训练集，而INA视频是未裁剪的长视频，总长度为77小时。INA视频分为培训、验证和测试集。训练集、验证集和测试集中分别有1336、310和329个动作片段。</p><p>总之，MEXaction2 dataset的特点是未裁剪的视频非常长，注释片段只占整个视频的很小一部分。</p><h3 id="D-MUTITHUMOS"><a href="#D-MUTITHUMOS" class="headerlink" title="D.MUTITHUMOS"></a>D.MUTITHUMOS</h3><p>MUTITHUMOS是一个密集的，多类，帧明智标签视频数据集，包括400个视频30小时，38,690个65个类的注释。平均每帧有1.5个标签，每段视频有10.5个动作类。这是THUMOS的增强版。目前，我们只在2017的论文“‘Learning Latent Super-Events to Detect Multiple Activities in Videos”中看到对该数据集的评价</p><h3 id="E-CHARADES"><a href="#E-CHARADES" class="headerlink" title="E.CHARADES"></a>E.CHARADES</h3><p>Charades是未删减的视频，其中包含9,848个室内视频，(7985个训练数据，1863年测试数据)，以及来自267个不同人的157个课程。每个视频大约30秒。每个视频都有多个注释，每个动作的开始时间和结束时间。</p><h3 id="F-AVA"><a href="#F-AVA" class="headerlink" title="F.AVA"></a>F.AVA</h3><p>AVA是一个时空本地化的原子视觉动作数据集。它包含了430个15分钟长的电影片段，并注释了80个动作。有38.6万个标记片段，61.4万个标记包围框和8.1万个人员轨迹。总共有158万标记的行为，每个人经常有多个标记。</p><p>接下来，我们总结和比较这些数据集显示表2。</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/image-20201114213744116.png" alt=""></p><h2 id="4-评价指标"><a href="#4-评价指标" class="headerlink" title="4.评价指标"></a>4.评价指标</h2><h3 id="A-基本概念"><a href="#A-基本概念" class="headerlink" title="A.基本概念"></a>A.基本概念</h3><p>在二分类问题当中，TP代表True Positive，FP代表False Positive，TN代表True Negative，而FN代表False Negative。这四个参数被用来计算多种性能评价指标。给出了四个参数的逻辑细节在表3中。</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/image-20201114214140041.png" alt=""></p><p>其中，在实际的二进制分类中，positive-1标签指的是你比较关心的样本，比如一个动作或者一个异常事件。</p><h4 id="1-ACCURACY"><a href="#1-ACCURACY" class="headerlink" title="1)ACCURACY"></a>1)ACCURACY</h4><p>准确度是指正确分类样本的比例。它被用来评价分级机的性能。</p><script type="math/tex; mode=display">accuracy=\frac{rP+TN}{TP + TN + FP + FN}=\frac{TP+TN}{ALL}(1)</script><h4 id="2-RECALL"><a href="#2-RECALL" class="headerlink" title="2)RECALL"></a>2)RECALL</h4><p>召回率是正确预测的范围。准确的说，找回是测试集中确定了多少真的positive样本。它的公式如下。</p><script type="math/tex; mode=display">recall=\frac{TP}{TP+FN}（2）</script><h4 id="3-PRECISION"><a href="#3-PRECISION" class="headerlink" title="3)PRECISION"></a>3)PRECISION</h4><p>准确的说，准度是预测真实positive样本占预测结果的百分比。它的公式如下。</p><script type="math/tex; mode=display">Precision=\frac{TP}{TP+FP}=\frac{TP}{n}(3)</script><p>其中，n为真positive和假positive之和，n为系统识别的样本总数。</p><h4 id="4-INTERSECTION-OVER-UNION-IoU"><a href="#4-INTERSECTION-OVER-UNION-IoU" class="headerlink" title="4)INTERSECTION-OVER-UNION (IoU)"></a>4)INTERSECTION-OVER-UNION (IoU)</h4><p>IoU可以理解为模型预测的检测框与图像中目标检测的地面真实值的重叠。其实就是检测的准确性，计算公式为探测结果与地面真值的交点，并与两者的联合进行比较。</p><script type="math/tex; mode=display">IoU=\frac{predicted detection box\cap ground truth}{predicted detection box\cup ground truth}(4)</script><p>IoU用于检查预测结果与地面真实值之间的IoU是否大于预测阈值。我们通常把0.5作为阈值。如果IoU大于0.5，则该对象被识别为“检测成功”，否则被识别为“漏报”。在时间动作检测中，将IoU转化为时间的t-IoU，该t-IoU只有一维。</p><h3 id="B-评价指标"><a href="#B-评价指标" class="headerlink" title="B. 评价指标"></a>B. 评价指标</h3><h3 id="C-平均召回-AVERAGE-RECALL-AR"><a href="#C-平均召回-AVERAGE-RECALL-AR" class="headerlink" title="C.平均召回(AVERAGE RECALL,AR)"></a>C.平均召回(AVERAGE RECALL,AR)</h3><p>AR是时间动作建议区域生成的评价指标。因为时间动作建议区域生成不需要分类，它仅仅只需要去发现建议区域。因此，我们发现的时间动作建议区域是否完整，可以用来评估该方法的性能。所有我们经常使用AR来对此进行判断</p><script type="math/tex; mode=display">AR=\frac{sum of the videos recalled}{total number of videos}(5)</script><h3 id="D-均值平均精度-MEAN-AVERAGE-PRECISION-mAP"><a href="#D-均值平均精度-MEAN-AVERAGE-PRECISION-mAP" class="headerlink" title="D. 均值平均精度(MEAN AVERAGE PRECISION,mAP)"></a>D. 均值平均精度(MEAN AVERAGE PRECISION,mAP)</h3><p>在时间动作定位任务中，mAP是最常用的评价指标。一般来说，我们在t-IoU = 0.5的情况下比较mAp。</p><p>简单地说， Precision (P)是给定视频中单个类的正确检测程度。例如，对于给定的单个视频，在公式中显示了类C的精度。</p><script type="math/tex; mode=display">P=\frac{TP}{TP + FP}=\frac{number of predicted correct proposals}{total mumber of predicted proposals}(6)</script><p>由于测试集中有很多视频，平均精度(AP)是类C中所有视频的平均精度。同时，由于测试集视频对应的类也很多，所以平均平均精度就是所有测试视频中所有类的平均精度。</p><script type="math/tex; mode=display">mAP=\frac{the sum of average precision of all classes}{total number of videos in testing set}(7)</script><p>总之，在某t-IoU下，P是某类C在视频中预测建议区域的准确性。AP是视频中所有类别的预测建议的平均精度。MAP是所有测试视频中所有类的预测建议的平均精度的平均值。在标准评价方案下，几乎所有的文献都报道了不同阈值的t-IoU下的mAP</p><h2 id="5-最近的方法和发展"><a href="#5-最近的方法和发展" class="headerlink" title="5.最近的方法和发展"></a>5.最近的方法和发展</h2><h3 id="A-全监督时间动作定位-FULLY-SUPETVISED-TEMPORAL-ACTION-LOCALIZATION-F-TAL"><a href="#A-全监督时间动作定位-FULLY-SUPETVISED-TEMPORAL-ACTION-LOCALIZATION-F-TAL" class="headerlink" title="A.全监督时间动作定位(FULLY-SUPETVISED TEMPORAL ACTION LOCALIZATION,F-TAL)"></a>A.全监督时间动作定位(FULLY-SUPETVISED TEMPORAL ACTION LOCALIZATION,F-TAL)</h3><h4 id="1-全监督学习"><a href="#1-全监督学习" class="headerlink" title="1)全监督学习"></a>1)全监督学习</h4><p>==全监督学习是训练一种智能算法将输入数据映射到标签的过程，其中每个训练数据都有其对应的表示其ground truth的标签==。我们经常学习的分类和回归是监督式学习的代表。在时间动作定位任务中，全监督采用训练集的标签，该标签既包含视频级类别标签，又包含动作片段的时间标注信息(包括动作的开始时间和结束时间)。</p><h4 id="2-目前具有代表性的方法"><a href="#2-目前具有代表性的方法" class="headerlink" title="2)目前具有代表性的方法"></a>2)目前具有代表性的方法</h4><p>很多方法(如S-CNN[14]和PSDF[18])通过滑动窗口生成建议区域，并将提案分类为C + 1类，即C动作类和一个背景类。其中，S-CNN使用了多级CNN时间动作定位捕获鲁棒的视频特征表示。为了精确的边界，CDC [19] (Convolutional- de -Convolutional)网络和TPC-Net [20] ((Temporal Preservation Convolutional network)网络被提出用于帧级的动作预测。边界敏感网络(Boundary Sensitive Network, BSN[21])是最近提出的一种用于定位时间边界的网络，并进一步整合到动作建议区域中。次年，BSN的作者提出了一个新的时间建议区域置信度评价机制和边界匹配机制BMN [72]。BMN可以同时生成一维边界概率和二维BM的置信度图。为了保证建议区域的完整性，SSN[22]引入了结构化时间金字塔，利用解耦的分类器对行动进行分类和确定完整性。此外，一些基于区域的方法(如R-C3D[23]和talo - net[24])提出将二维目标检测方法推广到一维时间动作定位。最近，为了精确动作定位而提出了TSA-Net [26]和Gaussian temporal modeling [25]。下面是性能比较。为了简单和公平，我们在THUMOS14数据集和各种代表性方法的出版物上对mAP@tIoU = 0.5进行性能比较，如表4所示。</p><p>近年来，随着各种新型网络的引进，准确率已达到最新的46.9%[26]。当然，与图像中的目标检测还有一定的差距，这也是目前难以实现大规模商业化的原因。但我们可以相信，随着技术的不断进步，精度一定会实现突破。</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/image-20201115121823022.png" alt=""></p><h3 id="B-弱监督时间动作定位-W-TAL"><a href="#B-弱监督时间动作定位-W-TAL" class="headerlink" title="B.弱监督时间动作定位(W-TAL)"></a>B.弱监督时间动作定位(W-TAL)</h3><p>由上节可知，目前的全监督学习技术在时间动作定位方面取得了很大的成功。因为许多现有的技术依赖于裁剪后的视频作为输入，例如：UCF101，他们有这些精确的时间注释。但在现实情况下，大多数视频都是未修剪并包含许多与目标动作无关的帧。因此，对时态标注的要求是非常困难的。具体原因总结如下:a)每个动作实例的帧级注释既昂贵又耗时。b)时间行为并没有明确的定义，这些时间行为的标注可能是因人而异的。</p><p>因此，弱监督学习方法越来越受欢迎。</p><h4 id="1-弱监督学习"><a href="#1-弱监督学习" class="headerlink" title="1)弱监督学习"></a>1)弱监督学习</h4><p>让我们看一看弱监督学习。这里有三种类型的弱监督学习。a)不完全弱监督学习。不完全监督，这只是训练数据的一小部分标记，而其他数据没有标记。例如，在图像分类中，我们可以很容易地从网上得到大量的图像，但由于人工成本昂贵，只有少数图像有注释。b)不精确弱监督学习。也就是说训练数据只有粗粒度的标签。我们还以图像分类为例。我们通常有图像级标签，但没有对象级标签。c)不准确弱监督学习。也就是说，给我们的标签并不总是真实的。例如，当图像注释器疲劳或者粗心大意的时候，或者一些图像很难分类的时候，就会出现这种情况。</p><p>由上可知，弱监督时间定位在训练过程中只有视频级标签，没有帧级时间标注，属于第二类弱监督，即不精确监督。</p><h4 id="2-目前具有代表性的方法-1"><a href="#2-目前具有代表性的方法-1" class="headerlink" title="2)目前具有代表性的方法"></a>2)目前具有代表性的方法</h4><p>目前基于弱监督的定位方法很少，仅依赖于视频级的类标签来实现时间动作定位。受图像中弱监督目标检测的启发，研究人员对UntrimmedNet[29]和Hide-and-seek [30]进行了研究。UntrimmedNet是第一个提出动作识别和弱监督动作检测的公司。它是学习单标签动作分类和检测的一个端到端模型。STPN [31]是一个深度神经网络，依赖于分类。这个网络的总体结构如下:将视频分为N个片段，注意力模块可以识别关键片段的稀疏子集。然后我们就可以得到在分类标签预测过程中各个环节的重要性。因此，它能够通过自适应时间池化生成相应的类别标签和区间建议。AutoLoc [32]尝试根据CAS的阈值直接预测不同于以往弱监督时间动作检测的时间边界。==其主要思想是鼓励动作部分外的平均分低于动作类内的平均分==。W-TALC [33] 引入一种新的函数来进行K-max多实例学习，挖掘同一类局部实例之间的协同活动关系。为了解决分类器所关心的视频帧的碎片化和动作的完整性问题，Hide-and-seek[30]随机隐藏一些帧，迫使剩余注意力在每次训练中学习辨别度较低的视频帧。虽然，它不能保证在每次训练中都能发现新零件。结果表明，该方法对空间目标检测效果良好，但对时间动作定位效果不佳。Step-by-step erasion, one-by-one collection 对多个分类器进行擦除和训练，直接合并每个分类器的预测片段。性能好了一些，但是它花费更多的时间和计算。随后，CMCS[35]提出了一种具有多样性损失的多分支网络结构，用于动作完整性建模。与此同时，他们提出了一个方案，生成一个hard negative 视频来分离上下文。虽然本文的重点不是背景类，但它启发了接下来的三个作品，即BaSNet[36]，background modeling[37]和LPAT [38]。在没有考虑背景类别的情况下，将背景帧误分类为动作类别，导致大量FPs。在BasNet中，为了构造背景类的负样本，在另一个网络中引入注意模块来抑制背景响应。另外两部作品从不同的角度考虑背景阶级，有效地抑制了背景的影响。最后，它们都提高了定位的准确性。</p><p>以下是在THUMOS14数据集上的性能比较，与全监督学习和各种代表性方法发表的标准相同，如表5所示</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/image-20201115130532292.png" alt=""></p><h4 id="3）对W-TAL问题的见解"><a href="#3）对W-TAL问题的见解" class="headerlink" title="3）对W-TAL问题的见解"></a>3）对W-TAL问题的见解</h4><p>近年来，多用例学习(multiple instance learning, MIL)被应用于W-TAL学习中。MIL模型不是使用一组单独标记的实例来学习，而是接收一组标记的包，每个包包含许多实例。如果我们把视频中的动作实例看作一个包，把视频级别的注释看作标签，那么W-TAL可以被表述为一个多实例学习的过程。</p><p>时序类激活映射(Temporal class activation mapping，T-CAM)或类激活序列(r Class activation sequence ，CAS)是近年来出现的另一种W-TAL方法。CNN可视化显示，CNN的卷积层作为动作探测器执行，尽管对活动的位置没有监督。类激活序列说明，CNN尽管接受过视频层次标签的训练，但仍然能够具有本地化能力。此外，基于弱监督目标检测的其他研究，如交互式标注和生成对抗训练，也对W-TAL的研究有所启发。</p><p>综上所述，弱监督学习降低了劳动和时间成本，但也增加了时间检测的难度。但对于大多数动作类的大多数视频剪辑来说，效果似乎还不错。当然，仍有很大的改进空间</p><h2 id="5-未来方向和发展趋势"><a href="#5-未来方向和发展趋势" class="headerlink" title="5.未来方向和发展趋势"></a>5.未来方向和发展趋势</h2><p>时间动作定位的应用实际上会越来越广泛，未来的发展趋势可能集中但不限于以下几方面</p><p>a)精度和效率的改进。通过与二维卷积法和三维卷积法的比较，二维卷积法的精度更高，但效率较低。如何更好地发挥二者的优势是一个可能的研究方向</p><p>b)动作检测将从时间动作检测扩展到时空动作检测[39]。也就是说，我们应该从一维的时间间隔检测到二维的时空盒，这样可以更全面的检测动作</p><p>c)在线视频的动作检测。这是一个处理视频流的过程，需要在线检测动作的类别，但检测时间过后无法知道内容。在线的设置更符合需要实时检测或预警的监控视频的要求，如异常检测[41]。</p><p>d)时间动作定位的弱监督学习将会越来越受欢迎。在许多任务中，由于数据标注过程成本高昂，难以获得完整的监管信息。</p><p>e)视频是一种包含图像和音频的多模态数据。是否利用音频信息辅助时间动作定位是值得考虑的方向。正如Aytar等人使用图像辅助音频分析[45]。</p><h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6.结论"></a>6.结论</h2><p>在本文中，我们对时间动作定位进行了全面的概述。我们从时间划分的角度分析了相关技术:传统方法和深度学习方法。接下来我们总结基准数据集和分析评估指标。然后回顾了时间动作定位从完全监督学习到弱监督学习方法的最新进展。总之，我们试图给出时间行为本土化的相关性和现状。同时，我们也希望对时间动作定位感兴趣的读者有所帮助。</p><p>时间动作定位是视频理解领域的一个研究热点，具有很大的复杂性和挑战性。但是，我们相信在不久的将来，深度学习技术的应用可以改善结果，任务也会变得更加容易。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;[toc]&lt;/p&gt;
&lt;h1 id=&quot;A-Survey-on-Temporal-Action-Localization&quot;&gt;&lt;a href=&quot;#A-Survey-on-Temporal-Action-Localization&quot; class=&quot;headerlink&quot; title=&quot;A Survey on Temporal Action Localization&quot;&gt;&lt;/a&gt;A Survey on Temporal Action Localization&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;摘要:&lt;/strong&gt;在计算机视觉中，时间动作定位是视频理解中最关键也是最具挑战性的问题之一。由于其广泛的应用，近年来引起了广泛的关注日常生活应用。时间动作定位技术已经取得了很大的进展，特别是最近深度学习的发展。而且在未裁剪的情况下，现在需要更多的时间动作定位视频。在这篇论文中，我们的目标是调查最新的技术和模型的视频时间行动定位。主要包括相关技术、一些基准数据集和评价时间动作定位的度量。此外，我们从两个方面总结了时间动作定位各方面:全监督学习和弱监督学习。并列举了几部具有代表性的作品并比较他们各自的表现。最后，对其进行了深入分析，并提出了发展前景研究方向，并总结调查。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;关键词&lt;/strong&gt;：动作检测，计算机视觉，全监督学习，时间动作定位，弱监督学习。&lt;/p&gt;
&lt;h2 id=&quot;1-引言&quot;&gt;&lt;a href=&quot;#1-引言&quot; class=&quot;headerlink&quot; title=&quot;1.引言&quot;&gt;&lt;/a&gt;1.引言&lt;/h2&gt;&lt;p&gt;随着视频数量急剧的增长，视频理解成为了计算机视觉领域的一个热点问题和具有挑战性的方向。这个视频理解发个信包括许多子研究方向，包括在夏威夷，被CVPR举办的ActivityNet 挑战2017，这个网络一共提出了5个任务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;未裁剪的视频分类(Untrimmed Video Classification )&lt;/li&gt;
&lt;li&gt;裁剪后的行动识别( Trimmed Action Recognition)&lt;/li&gt;
&lt;li&gt;时间动作检测( Temporal Action Proposals)&lt;/li&gt;
&lt;li&gt;时间动作定位(Temporal Action Localization)&lt;/li&gt;
&lt;li&gt;视频中密集的字幕事件(Dense-Captioning Events in Videos)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在最近的调查中，我们关注的是时间动作定位，也就是上面列出的第四个。它需要检测包含目标动作的时间间隔。对于长时间的&lt;strong&gt;未裁剪的视频&lt;/strong&gt;，时间动作定位主要解决两个任务，识别和定位。特别是,a)动作发生的起始时间和终止时间,b)每个提案的类别是什么属于(如挥手、爬山、扣篮)。当然，一个视频可能包含一个或多个行动剪辑(action clips),所以时间动作定位是要开发模型和技术来提供计算机视觉应用所需要的最基本的信息:动作是什么，动作什么时候发生?我们将这个任务作为动作定位，或时间动作定位，或动作检测。&lt;/p&gt;
&lt;p&gt;虽然动作识别和动作本地化都是视频理解里面很重要的任务，但是时间动作定位比动作识别更加具有挑战性。动作识别和动作定位的关系和图像检测类似于图像识别和图像检测。但是由于时间连续信息(temporal series information),时间动作定位比图像检测更见困难。困难主要来自以下几个方面：&lt;strong&gt;a)&lt;/strong&gt;时间信息，由于1维时间连续信息，时间动作定位不能使用静态图片信息，它必须结合时间连续信息。&lt;strong&gt;b)&lt;/strong&gt;与目标检测不同的是，边界对象通常是非常清晰的，所以我们可以为对象标记一个更清晰的边界框。然而，可能没有关于动作的确切时间范围合理定义，所以，不可能给一个动作开始和结束的准确边界。&lt;strong&gt;c)&lt;/strong&gt;大的时间跨度，时间动作片段的跨度可以是非常大的，比如，挥手可能只几秒钟但是攀岩和骑自行车能够持续十几秒。它们时间跨度在长度上的不同，是的提取检测(extract proposals)很困难。另外，在开放的环境当中，这里也又许多问题，例如多尺度，多目标和相机移动。&lt;/p&gt;
&lt;p&gt;时间动作定位非常贴近我们的生活，它具有广泛的应用前景和社会价值在视频概况(video summarization)、公共视频监控、技能评估和日常生活安全。所以它在最最近几年得到了广泛的关注。与“动作检测”有关的出版物总数约为324127份，近二十年来包括书籍、期刊、论文、会议论文、专利和一些科技成果。下面我们主要分析出版学术和回忆论文的趋势动作检测，如同&lt;strong&gt;图1&lt;/strong&gt;所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/paper/image-20201027193624091.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;本调查旨在帮助对时态动作本地化感兴趣的初学者。它提供一个概括动作定位的方法和最新进展，本文余下部分组织如下。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第二节概述相关技术。&lt;/li&gt;
&lt;li&gt;第三节介绍基本的时间动作定位数据集&lt;/li&gt;
&lt;li&gt;第四节描述模型的性能评估指标&lt;/li&gt;
&lt;li&gt;第五节从全监督和弱监督两方面，提供一个时间动作定位模型和方法的概述&lt;/li&gt;
&lt;li&gt;第六节讨论现在的挑战和建议未来的方向&lt;/li&gt;
&lt;li&gt;第七节总结本论文&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="论文学习" scheme="http://example.com/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="时间动作定位" scheme="http://example.com/tags/%E6%97%B6%E9%97%B4%E5%8A%A8%E4%BD%9C%E5%AE%9A%E4%BD%8D/"/>
    
    <category term="时序动作定位" scheme="http://example.com/tags/%E6%97%B6%E5%BA%8F%E5%8A%A8%E4%BD%9C%E5%AE%9A%E4%BD%8D/"/>
    
    <category term="动作检测" scheme="http://example.com/tags/%E5%8A%A8%E4%BD%9C%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>hexo使用github action实现自动化部署</title>
    <link href="http://example.com/2021/05/30/hexo%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"/>
    <id>http://example.com/2021/05/30/hexo%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/</id>
    <published>2021-05-30T20:07:27.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h1 id="hexo使用github-action实现自动化部署"><a href="#hexo使用github-action实现自动化部署" class="headerlink" title="hexo使用github action实现自动化部署"></a>hexo使用github action实现自动化部署</h1><p>最近将hexo博客进行了美化，为了更“折腾”一点，决定实现一下hexo对应的自动化部署，毕竟网上的资料对应的也有不少，学习一下。</p><p>我自己的需求是</p><ul><li>将hexo、hexo生成的静态文件、博客源码都放在一起（个人感觉方便管理，免得创建许多仓库），然后hexo主要就在hexo分支上</li><li>在hexo分支上进行自动化，实现上传文件后自动部署。</li></ul><p>查看博客点击👉<a href="https://zhou-ning.github.io/">https://zhou-ning.github.io/</a></p><p>查看博客仓库点击👉<a href="https://github.com/zhou-ning/zhou-ning.github.io">https://github.com/zhou-ning/zhou-ning.github.io</a></p><span id="more"></span><p>在这里先说明一下我的项目的分支结构，我是将项目放到了<strong><a href="https://github.com/zhou-ning/zhou-ning.github.io">zhou-ning.github.io</a></strong>下，下面有master、gh-pages、source、hexo四个分支</p><ul><li>master，啥也不干起说明作用</li><li>gh-pages，放hexo生成的静态文件</li><li>source，存放源文件</li><li>hexo，存放hexo文件，并部署了自动化</li></ul><h2 id="上传hexo项目文件"><a href="#上传hexo项目文件" class="headerlink" title="上传hexo项目文件"></a>上传hexo项目文件</h2><p>🤗<strong>如果会将hexo项目安全上传到github上的可以直接跳过这步了。</strong>感觉这步写的有点啰嗦</p><p>一般来说一个hexo项目如下图所示</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210530203146315.png" alt="image-20210530203146315"></p><p>本人上传的之前是先直接删除了下面几样东西：</p><ul><li><code>.github</code>文件夹，包括根目录和<code>themes</code>里面的</li><li>因为<code>themes</code>里面的主题有的是<code>git clone</code>来的,所以我也给删除了<code>.git</code>文件夹</li></ul><p>然后将剩下的文件，上传到新的仓库或者某个仓库的某个分支，我是给上传到了<strong><a href="https://github.com/zhou-ning/zhou-ning.github.io">zhou-ning.github.io</a></strong>下的hexo分支</p><h2 id="生成密钥"><a href="#生成密钥" class="headerlink" title="生成密钥"></a>生成密钥</h2><p>因为需要将hexo项目生成的静态文件上传到github上（跟本地上传类似），所以需要生成密钥进行上传。</p><p>生成命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;Hexo Deploy Key&quot; -f github-deploy-key -N &quot;&quot;</span><br></pre></td></tr></table></figure><p>在windows下可以通过<code>git bash</code>生成，相信在配置git的时候应该了解过</p><p><code>ssh-keygen</code>命令讲解可以看的➡<a href="https://www.linuxcool.com/ssh-keygen">https://www.linuxcool.com/ssh-keygen</a></p><p>这会在当前目录生成两个文件：</p><ul><li>github-deploy-key —— 私钥</li><li>github-deploy-key.pub —— 公钥</li></ul><h2 id="配置私钥"><a href="#配置私钥" class="headerlink" title="配置私钥"></a>配置私钥</h2><p>把<strong>私钥</strong>放在hexo项目的代码仓库当中的Secrets中，这是为了配置action的时候使用，在我这里就是<strong><a href="https://github.com/zhou-ning/zhou-ning.github.io">zhou-ning.github.io</a></strong>项目(hexo分支)</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210530211649771.png" alt="image-20210530211649771"></p><p>依次点击<code>Setting</code>、<code>Secrets</code>、<code>New repository secret</code></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210530211935519.png" alt="image-20210530211935519"></p><p>输入名字HEXO_DEPLOY_KEY，以及对应的内容，然后就可以生成Repository secrets了</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210530212045237.png" alt="image-20210530212045237"></p><h2 id="配置公钥"><a href="#配置公钥" class="headerlink" title="配置公钥"></a>配置公钥</h2><p>把公钥放在需要上传静态文件的项目中，在我这里也是<strong><a href="https://github.com/zhou-ning/zhou-ning.github.io">zhou-ning.github.io</a></strong>项目(gh-pages分支)</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210530212318098.png" alt="image-20210530212318098"></p><p>依次点击<code>Setting</code>、<code>Deploy keys</code>、<code>add deploy key</code></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210530212539068.png" alt="image-20210530212539068"></p><p>输入名字HEXO_DEPLOY_PUB ，以及对应的内容，然后记得勾选<code>Allow write access</code>,然后点击<code>Add key</code></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210530212652197.png" alt="image-20210530212652197"></p><h2 id="配置其他内容"><a href="#配置其他内容" class="headerlink" title="配置其他内容"></a>配置其他内容</h2><p>在我这里面要配置<code>gitalk</code>的CLIENT_ID和CLIENT_SECRET的值，配置方法和配置私钥是一样的</p><p>CLIENT_ID：</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210531230828953.png" alt="image-20210531230828953"></p><p>CLIENT_SECRET：</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210531230912586.png" alt="image-20210531230912586"></p><p>最终</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210531231008588.png" alt="image-20210531231008588"></p><h2 id="创建-Workflow"><a href="#创建-Workflow" class="headerlink" title="创建 Workflow"></a>创建 Workflow</h2><p>在 Hexo 的仓库或者hexo中创建一个新文件：<code>.github/workflows/deploy.yml</code>，文件名可以自己取，但是一定要放在 <code>.github/workflows</code> 目录中，文件的内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Hexo</span> <span class="string">Deploy</span></span><br><span class="line"><span class="comment"># 要触发的分支</span></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line">  <span class="attr">push:</span></span><br><span class="line">    <span class="attr">branches:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">hexo</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">build:</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">if:</span> <span class="string">github.event.repository.owner.id</span> <span class="string">==</span> <span class="string">github.event.sender.id</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Checkout</span> <span class="string">source</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">actions/checkout@v2</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">        <span class="comment"># 设置对应的分支，本文这里是hexo分支</span></span><br><span class="line">          <span class="attr">ref:</span> <span class="string">hexo</span></span><br><span class="line"></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Setup</span> <span class="string">Node.js</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">actions/setup-node@v1</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">node-version:</span> <span class="string">&#x27;12&#x27;</span></span><br><span class="line"></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Setup</span> <span class="string">Hexo</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="attr">ACTION_DEPLOY_KEY:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.HEXO_DEPLOY_KEY</span> <span class="string">&#125;&#125;</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          mkdir -p ~/.ssh/</span></span><br><span class="line"><span class="string">          echo &quot;$ACTION_DEPLOY_KEY&quot; &gt; ~/.ssh/id_rsa</span></span><br><span class="line"><span class="string">          chmod 700 ~/.ssh</span></span><br><span class="line"><span class="string">          chmod 600 ~/.ssh/id_rsa</span></span><br><span class="line"><span class="string">          ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts</span></span><br><span class="line"><span class="string">          ## 设置自己邮箱和github用户名</span></span><br><span class="line"><span class="string">          git config --global user.email &quot;1767508581@qq.com&quot;</span></span><br><span class="line"><span class="string">          git config --global user.name &quot;zhou-ning&quot;</span></span><br><span class="line"><span class="string">          npm install hexo-cli -g</span></span><br><span class="line"><span class="string">          npm install</span></span><br><span class="line"><span class="string"></span>      <span class="comment">### 设置gitalk,不需要可以删除掉</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Set</span> <span class="string">gitalk</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="attr">CLIENT_ID:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.CLIENT_ID</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">CLIENT_SECRET:</span> <span class="string">$&#123;&#123;</span> <span class="string">secrets.CLIENT_SECRET&#125;&#125;</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          sed -i &#x27;639s/123/$CLIENT_ID/&#x27; ./themes/next/_config.yml</span></span><br><span class="line"><span class="string">          sed -i &#x27;640s/123/$CLIENT_SECRET/&#x27; ./themes/next/_config.yml</span></span><br><span class="line"><span class="string"></span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Deploy</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          hexo clean</span></span><br><span class="line"><span class="string">          hexo deploy</span></span><br></pre></td></tr></table></figure><p> 简单来说，就是上传文件到hexo的时候，他会触发这个Workflow，然后构建ubuntu最新的环境，接着构建nodejs环境、git环境、hexo环境，再设置gitalk，最后再运行<code>hexo clean</code>、<code>hexo deploy</code>进行上传</p><p>但是这里存在一个问题如果我们hexo分支不在default分支，默认是触发不了的Workflow的，需要将hexo切换成default分支才能触发。切换的方法是</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210601104734139.png" alt="image-20210601104734139"></p><p>然后就可以通过上传进行触发了。</p><p>后续的话，将master切换回default也是可以触发的。</p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>配置自动化部署其实不是很难，就是刚刚接触github action啥都不懂耽误了很久，在这小结一下，方便自己日后换电脑的时候使用。</p><p><strong>参考：</strong><a href="https://zhuanlan.zhihu.com/p/170563000">https://zhuanlan.zhihu.com/p/170563000</a></p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;hexo使用github-action实现自动化部署&quot;&gt;&lt;a href=&quot;#hexo使用github-action实现自动化部署&quot; class=&quot;headerlink&quot; title=&quot;hexo使用github action实现自动化部署&quot;&gt;&lt;/a&gt;hexo使用github action实现自动化部署&lt;/h1&gt;&lt;p&gt;最近将hexo博客进行了美化，为了更“折腾”一点，决定实现一下hexo对应的自动化部署，毕竟网上的资料对应的也有不少，学习一下。&lt;/p&gt;
&lt;p&gt;我自己的需求是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将hexo、hexo生成的静态文件、博客源码都放在一起（个人感觉方便管理，免得创建许多仓库），然后hexo主要就在hexo分支上&lt;/li&gt;
&lt;li&gt;在hexo分支上进行自动化，实现上传文件后自动部署。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;查看博客点击👉&lt;a href=&quot;https://zhou-ning.github.io/&quot;&gt;https://zhou-ning.github.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;查看博客仓库点击👉&lt;a href=&quot;https://github.com/zhou-ning/zhou-ning.github.io&quot;&gt;https://github.com/zhou-ning/zhou-ning.github.io&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="其他" scheme="http://example.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
    <category term="hexo" scheme="http://example.com/tags/hexo/"/>
    
    <category term="next" scheme="http://example.com/tags/next/"/>
    
    <category term="github action" scheme="http://example.com/tags/github-action/"/>
    
  </entry>
  
  <entry>
    <title>Next主题美化</title>
    <link href="http://example.com/2021/05/22/next%E7%BE%8E%E5%8C%96/"/>
    <id>http://example.com/2021/05/22/next%E7%BE%8E%E5%8C%96/</id>
    <published>2021-05-22T22:02:23.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Next主题美化"><a href="#Next主题美化" class="headerlink" title="Next主题美化"></a>Next主题美化</h1><p>最近使用hexo的next主题在github上搭建了一个博客，但是发现这个next主题并不完全是自己想要的，所以还需要美(zhe)化（ten）一下。主要折腾了三个方面：</p><ul><li>鼠标点击特效</li><li>个性化回到顶部</li><li>打字特效</li><li>上传文件中带有READ.md</li></ul><span id="more"></span><h2 id="鼠标点击特效"><a href="#鼠标点击特效" class="headerlink" title="鼠标点击特效"></a>鼠标点击特效</h2><p>添加鼠标点击礼花特效🎉，效果如下</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/鼠标点击礼花特效.gif" alt="鼠标点击礼花特效"></p><p>在<code>themes\next\source\js\cursor\</code>目录下 创建<strong>fireworks.js</strong>，具体<strong>fireworks.js</strong>的内容可以点击👉<a href="https://github.com/zhou-ning/hexo-theme-next/blob/master/source/js/cursor/fireworks.js">fireworks.js</a>进行查看(不展示因为实在是太长了)</p><p>然后在主题自定义布局文件<code>themes\next\layout\_custom\custom.swig</code>中添加以下代码：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;# 鼠标点击特效 #&#125;</span><br><span class="line">&#123;% <span class="keyword">if</span> theme.cursor_effect == <span class="string">&quot;fireworks&quot;</span> %&#125;</span><br><span class="line">  &lt;script <span class="keyword">async</span> src=<span class="string">&quot;/js/cursor/fireworks.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><p>如果 <strong>custom.swig</strong> 文件不存在，需要手动在<code>themes\next\layout\_custom</code>下创建并在<code>themes\next\layout\_layout.swig</code>布局页面中 <strong>body</strong> 末尾引入：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"> ...</span><br><span class="line"> &#123;%- if theme.pjax %&#125;</span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;pjax&quot;</span>&gt;</span></span><br><span class="line">  &#123;%- endif %&#125;</span><br><span class="line">  &#123;% include &#x27;_third-party/math/index.swig&#x27; %&#125;</span><br><span class="line">  &#123;% include &#x27;_third-party/quicklink.swig&#x27; %&#125;</span><br><span class="line"></span><br><span class="line">  &#123;&#123;- next_inject(&#x27;bodyEnd&#x27;) &#125;&#125;</span><br><span class="line">  &#123;%- if theme.pjax %&#125;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  &#123;%- endif %&#125;</span><br><span class="line">  &#123;% include &#x27;_custom/custom.swig&#x27; %&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>记住是在<strong>layout</strong>文件夹下创建对应的<strong>custom.swig</strong> 文件，别创建错了。</p><p>最后在主题配置文件<code>themes\next\_config.yml</code>中添加以下代码：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mouse click effect: fireworks | explosion | love | text</span></span><br><span class="line"><span class="attr">cursor_effect:</span> <span class="string">fireworks</span></span><br></pre></td></tr></table></figure><p>当然点击特效还有其他的，可以参考：<a href="http://yearito.cn/posts/hexo-theme-beautify.html">http://yearito.cn/posts/hexo-theme-beautify.html</a></p><h2 id="个性化回到顶部"><a href="#个性化回到顶部" class="headerlink" title="个性化回到顶部"></a>个性化回到顶部</h2><p>个性化回到顶端是我自己比较喜欢的，也是从上面那个参考那里借鉴的（读书人的事，怎么能咳咳，扯远了），是一个小猫然后点击可以回到顶端，效果如下：</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/个性化back2top.gif" alt="个性化back2top"></p><p>首先，下载该图片，点击👉<a href="https://github.com/zhou-ning/hexo-theme-next/blob/master/source/images/scroll.png">小猫图片</a></p><p>然后在<code>themes\next\source\css\_common\components\back-to-top.styl</code>里面<strong>添加</strong>(不是覆盖)</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">//自定义回到顶部样式</span><br><span class="line"><span class="keyword">@media</span> screen <span class="keyword">and</span> (<span class="attribute">min-width</span>: <span class="number">900px</span>) &#123;</span><br><span class="line"><span class="selector-class">.back-to-top</span> &#123;</span><br><span class="line">  <span class="attribute">right</span>: <span class="number">60px</span>;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">70px</span>;  //图片素材宽度</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">900px</span>;  //图片素材高度</span><br><span class="line">  <span class="attribute">top</span>: -<span class="number">900px</span>;</span><br><span class="line">  <span class="attribute">bottom</span>: unset;</span><br><span class="line">  <span class="attribute">transition</span>: all .<span class="number">5s</span> ease-in-out;</span><br><span class="line">  <span class="attribute">background</span>: <span class="built_in">url</span>(<span class="string">&quot;/images/scroll.png&quot;</span>);</span><br><span class="line">  <span class="attribute">position</span>: fixed</span><br><span class="line">  //隐藏箭头图标</span><br><span class="line">  &gt; i &#123;</span><br><span class="line">    display: none;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  &amp;<span class="selector-class">.back-to-top-on</span> &#123;</span><br><span class="line">    <span class="attribute">bottom</span>: unset;</span><br><span class="line">    <span class="attribute">top</span>: <span class="number">100vh</span> &lt; (<span class="number">900px</span> + <span class="number">200px</span>) ? <span class="built_in">calc</span>( <span class="number">100vh</span> - <span class="number">900px</span> - <span class="number">200px</span> ) : <span class="number">0px</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure><p>在主题配置文件<code>themes\next\_config.yml</code>中打开<strong>back2top</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">back2top:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Back to top in sidebar.</span></span><br><span class="line">  <span class="attr">sidebar:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Scroll percent label in b2t button.</span></span><br><span class="line">  <span class="attr">scrollpercent:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="打字特效"><a href="#打字特效" class="headerlink" title="打字特效"></a>打字特效</h2><p>如果你开评论的话，可以考虑加入这个特效，感觉还挺炫酷。</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/打字特效.gif" alt="打字特效"></p><p>首先，点击<a href="https://github.com/zhou-ning/hexo-theme-next/blob/master/source/js/activate-power-mode.min.js">activate-power-mode.min.js</a>下载相应的脚本，并置于 <code>themes\next\source\js\</code> 目录下。</p><p>在主题自定义布局文件<code>themes\next\layout\_custom\custom.swig</code>中添加以下代码：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;# 打字特效 #&#125;</span><br><span class="line">&#123;% if theme.typing_effect %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;/js/activate-power-mode.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="handlebars"><span class="xml"></span></span></span><br><span class="line"><span class="xml"><span class="handlebars">    POWERMODE.colorful = </span><span class="template-variable">&#123;&#123; <span class="name">theme.typing_effect.colorful</span> &#125;&#125;</span><span class="xml">;</span></span></span><br><span class="line"><span class="xml"><span class="handlebars">    POWERMODE.shake = </span><span class="template-variable">&#123;&#123; <span class="name">theme.typing_effect.shake</span> &#125;&#125;</span><span class="xml">;</span></span></span><br><span class="line"><span class="xml"><span class="handlebars">    document.body.addEventListener(&#x27;input&#x27;, POWERMODE);</span></span></span><br><span class="line"><span class="xml"><span class="handlebars">  </span></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><p>如果 custom.swig 文件不存在，需要手动新建并在布局页面中 body 末尾引入,这个上面说过了，就不多说了。</p><p>在主题配置文件<code>themes\next\_config.yml</code>中添加以下代码：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># typing effect</span></span><br><span class="line"><span class="attr">typing_effect:</span></span><br><span class="line">  <span class="attr">colorful:</span> <span class="literal">true</span>  <span class="comment"># 礼花特效</span></span><br><span class="line">  <span class="attr">shake:</span> <span class="literal">false</span>  <span class="comment"># 震动特效</span></span><br></pre></td></tr></table></figure><h2 id="上传文件中带有README-md"><a href="#上传文件中带有README-md" class="headerlink" title="上传文件中带有README.md"></a>上传文件中带有README.md</h2><p>我们知道hexo上传的文件当中只有css、js、html等文件，如果我们在根目录的source文件夹下添加README.md，又会变成html。这对于我这样的强迫症太难受。</p><p>解决方法是在根目录下(注意是根目录下，不是主题next目录下)的<strong>_config.yml</strong>的<code>skip_render</code>前面加上<code>README.md</code>，如下:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">skip_render:</span> <span class="string">README.md</span></span><br></pre></td></tr></table></figure><p>然后再使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure><p>最终可以看到</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/others/image-20210522214004389.png" alt="展示"></p><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>next主题的优化就告辞段落，目前我的需求基本满足了，如果有大佬想了解更多更深度的，可以参考：<a href="http://yearito.cn/posts/hexo-theme-beautify.html">http://yearito.cn/posts/hexo-theme-beautify.html</a></p><p>不过他的这个有点中有一个问题，就是custom.styl不存在了，这个可以参考这个issue：</p><p><a href="https://github.com/theme-next/hexo-theme-next/issues/982">https://github.com/theme-next/hexo-theme-next/issues/982</a></p><p>目前感觉自己折腾了一年的博客，从hexo到直接存在github上再到jekyll，最后又回到hexo，真实生命不息折腾不止，博客选择就到此结束吧。</p><p><strong>参考：</strong></p><ul><li><a href="http://yearito.cn/posts/hexo-theme-beautify.html">http://yearito.cn/posts/hexo-theme-beautify.html</a></li><li><a href="https://github.com/theme-next/hexo-theme-next/issues/982">https://github.com/theme-next/hexo-theme-next/issues/982</a></li><li><a href="https://www.zhihu.com/question/23934523">https://www.zhihu.com/question/23934523</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Next主题美化&quot;&gt;&lt;a href=&quot;#Next主题美化&quot; class=&quot;headerlink&quot; title=&quot;Next主题美化&quot;&gt;&lt;/a&gt;Next主题美化&lt;/h1&gt;&lt;p&gt;最近使用hexo的next主题在github上搭建了一个博客，但是发现这个next主题并不完全是自己想要的，所以还需要美(zhe)化（ten）一下。主要折腾了三个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;鼠标点击特效&lt;/li&gt;
&lt;li&gt;个性化回到顶部&lt;/li&gt;
&lt;li&gt;打字特效&lt;/li&gt;
&lt;li&gt;上传文件中带有READ.md&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="其他" scheme="http://example.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
    <category term="hexo" scheme="http://example.com/tags/hexo/"/>
    
    <category term="next" scheme="http://example.com/tags/next/"/>
    
  </entry>
  
  <entry>
    <title>编程更改镜像总结</title>
    <link href="http://example.com/2021/05/22/%E6%9B%B4%E6%94%B9%E9%95%9C%E5%83%8F/"/>
    <id>http://example.com/2021/05/22/%E6%9B%B4%E6%94%B9%E9%95%9C%E5%83%8F/</id>
    <published>2021-05-22T11:19:05.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h1 id="编程更改镜像总结"><a href="#编程更改镜像总结" class="headerlink" title="编程更改镜像总结"></a>编程更改镜像总结</h1><p>在学习编程的过程中，总是会遇到各种各样的网络问题（指包下载的网络问题），所以总结一下这些镜像源的更改，方便自己更快的下载这些包。因为本人电脑是windows系统的，所以注意总结windows系统下的镜像更改。</p><span id="more"></span><h2 id="python中pip更改镜像源"><a href="#python中pip更改镜像源" class="headerlink" title="python中pip更改镜像源"></a>python中pip更改镜像源</h2><p>pip安装包的时候默认都是从国外安装，网速堪忧，所以一般安装完python，都需要将自己使用的pip源进行更换。</p><p>windows下，直接在user目录中创建一个pip目录，如：C:\Users\xx\pip，新建文件pip.ini，内容如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>其中这个<strong>index-url</strong>的解释是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python软件包索引的基本URL（默认为https://pypi.org/simple）。这应该指向符合PEP 503（简单存储库API）的存储库或以相同格式布置的本地目录。</span><br></pre></td></tr></table></figure><p>我看有的博客也会叫再加一个<strong>extra-index-url</strong>参数，但是目前使用来看似乎不太需要。</p><p>关于<strong>index-url、extra-index-url</strong>的讲解可以参考<a href="https://pip.pypa.io/en/stable/cli/pip_install/#install-index-url">https://pip.pypa.io/en/stable/cli/pip_install/#install-index-url</a></p><p>当然其实也可以不创建该文件，但是需要我们安装的时候加上参数<code>-i</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -i 包名 https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><p>参考：<a href="https://blog.csdn.net/lambert310/article/details/52412059">https://blog.csdn.net/lambert310/article/details/52412059</a></p><h2 id="conda更改镜像源"><a href="#conda更改镜像源" class="headerlink" title="conda更改镜像源"></a>conda更改镜像源</h2><p>参考：<a href="https://blog.csdn.net/weixin_40871455/article/details/90071122">https://blog.csdn.net/weixin_40871455/article/details/90071122</a></p><h2 id="maven换源"><a href="#maven换源" class="headerlink" title="maven换源"></a>maven换源</h2><p>maven更改源比较简单。</p><ol><li><p>找到maven安装目录中的settings.xml</p></li><li><p>找到 \<mirrors>  &lt;/ mirrors&gt;标签，标签中添加mirror子节点，内容如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>aliyunmaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>阿里云公共仓库<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://maven.aliyun.com/repository/public<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>一般来说也也需要更改maven下载包的目录，不然他默认下载在c盘当中(我的c盘太小了，还是改改)</p><p>找到 \<localRepository> \</localRepository>,将其变成</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">localRepository</span>&gt;</span>D:\Program Files\MavenRepository<span class="tag">&lt;/<span class="name">localRepository</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="nodejs中npm换源"><a href="#nodejs中npm换源" class="headerlink" title="nodejs中npm换源"></a>nodejs中npm换源</h2><p>一般是更换淘宝的源</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config set registry https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure><p>配置后可通过下面方式来验证是否成功</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config get registry </span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;编程更改镜像总结&quot;&gt;&lt;a href=&quot;#编程更改镜像总结&quot; class=&quot;headerlink&quot; title=&quot;编程更改镜像总结&quot;&gt;&lt;/a&gt;编程更改镜像总结&lt;/h1&gt;&lt;p&gt;在学习编程的过程中，总是会遇到各种各样的网络问题（指包下载的网络问题），所以总结一下这些镜像源的更改，方便自己更快的下载这些包。因为本人电脑是windows系统的，所以注意总结windows系统下的镜像更改。&lt;/p&gt;</summary>
    
    
    
    <category term="其他" scheme="http://example.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
  </entry>
  
  <entry>
    <title>QTbinarytree</title>
    <link href="http://example.com/2021/05/20/QTbinarytree/"/>
    <id>http://example.com/2021/05/20/QTbinarytree/</id>
    <published>2021-05-20T23:13:23.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Qt绘制二叉树是大二时数据结构的一个实习题目，当时的功能要求如下：</p><ul><li>键盘输入二叉树结点序列（前序或层次），创建一棵二叉树<ul><li>实现<strong>SwapTree</strong>方法，以根结点为参数，交换每个结点的左子树和右子树（提示：前序递归）</li></ul></li><li>实现<strong>Find</strong>方法，查找值为<strong>key</strong>的结点，并输出该结点的所有祖先结点</li><li><strong>输入一棵二叉树的前序遍历序列和中序遍历序列，重构这棵二叉树（这个序列里面是不带空结点’#‘的）</strong></li></ul><span id="more"></span><p> 二叉树的前序和中序创建要求如下：</p><ul><li>要求键盘输入二叉树结点序列<ul><li>结点序列可以是前序，也可以是层次</li></ul></li><li><p>空结点以<strong>#</strong>表示</p><p>由题目可知呢主要就是可视化一颗二叉树，另外需要说清的是<strong>仅仅前序遍历是无法确定一颗二叉树的顺序的，但是如果前序中加上空节点‘#’，是可以确定的</strong></p></li></ul><p><strong>示例1（前序和层次的）：</strong></p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/数据结构/QTbinarytree.png" alt="QTbinarytree.png"></p><p><strong>示例2（前序=“ABC##DE#G##F###” 或者 层次=“AB#CD##EF#G####”）：</strong></p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/数据结构/QTbinarytree3.png" alt="QTbinarytree3"></p><p><strong>示例3（前序=”ABHFDECKG”和中序=”HBDFAEKCG”）：</strong></p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/数据结构/QTbinarytree4.png" alt="QTbinarytree4"></p><h2 id="主要建树思路"><a href="#主要建树思路" class="headerlink" title="主要建树思路"></a>主要建树思路</h2><ol><li>主要功能就前序构造、层次构造、交换节点、查找关键字、重新构建这几个，所以为了图便捷，就直接在Qt提供的ui界面上加上这几个菜单项，可以参考下图</li></ol><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/数据结构/QTbinarytree2.png" alt="QTbinarytree2"></p><ol><li><p>二叉树根据前序生成一颗树。编写了一个函数CreateBinTree，利用递归进行二叉树的生成。思路也比较简单可以看下面的代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//前序创造节点</span></span><br><span class="line"><span class="comment">//i代表第几个字母</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BinaryTree::CreateBinTree</span><span class="params">(QString &amp;str, BinTreeNode *&amp;Node,<span class="keyword">int</span> &amp;i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="comment">//  qDebug()&lt;&lt;str;</span></span><br><span class="line"><span class="keyword">if</span>(str[i]!=<span class="string">&#x27;#&#x27;</span>)<span class="comment">//说明不是空结点</span></span><br><span class="line">&#123;</span><br><span class="line">   Node=<span class="keyword">new</span> <span class="built_in">BinTreeNode</span>(str[i]);</span><br><span class="line">   Treesize++;</span><br><span class="line">   i++;</span><br><span class="line">   <span class="keyword">this</span>-&gt;<span class="built_in">CreateBinTree</span>(str,Node-&gt;left,i);</span><br><span class="line">   <span class="keyword">this</span>-&gt;<span class="built_in">CreateBinTree</span>(str,Node-&gt;right,i);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">   i++;</span><br><span class="line">   Node=<span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>二叉树的层次遍历生成一颗二叉树。这个利用队列来完成，利用队列遍历字符串，先将字符串第一个字符塞进队列作为根节点，然后按顺序遍历字符串并且创建对应的孩子节点，具体如下。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> j=<span class="number">0</span>;</span><br><span class="line">    Treesize=<span class="number">0</span>;</span><br><span class="line">    QQueue&lt;BinTreeNode *&gt;Q;</span><br><span class="line">    BinTreeNode *p=<span class="literal">nullptr</span>;</span><br><span class="line">    <span class="keyword">if</span>(str[j]==<span class="string">&#x27;#&#x27;</span>)   <span class="comment">//先创建根节点</span></span><br><span class="line">    &#123;</span><br><span class="line">        Treesize=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    root=<span class="keyword">new</span> <span class="built_in">BinTreeNode</span>(str[j]);</span><br><span class="line">    Treesize++;</span><br><span class="line">    Q.<span class="built_in">enqueue</span>(root);</span><br><span class="line">    j++;</span><br><span class="line"><span class="keyword">while</span>(j&lt;(str.<span class="built_in">size</span>()<span class="number">-1</span>))</span><br><span class="line">    &#123;</span><br><span class="line">       <span class="keyword">if</span>(Q.<span class="built_in">isEmpty</span>())</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">         <span class="keyword">else</span></span><br><span class="line">            p=Q.<span class="built_in">dequeue</span>();</span><br><span class="line"><span class="keyword">if</span>(str[j]!=<span class="string">&#x27;#&#x27;</span>)   <span class="comment">//如果字符不为‘#’，创建左结点</span></span><br><span class="line">        &#123;</span><br><span class="line">            p-&gt;left=<span class="keyword">new</span> <span class="built_in">BinTreeNode</span>(str[j]);</span><br><span class="line">            Treesize++;</span><br><span class="line">            Q.<span class="built_in">enqueue</span>(p-&gt;left);</span><br><span class="line">        &#125;</span><br><span class="line">         j++;</span><br><span class="line">        <span class="keyword">if</span>(str[j]!=<span class="string">&#x27;#&#x27;</span>)   <span class="comment">//如果字符不为‘#’，创建右结点</span></span><br><span class="line">        &#123;</span><br><span class="line">            p-&gt;right=<span class="keyword">new</span> <span class="built_in">BinTreeNode</span>(str[j]);</span><br><span class="line">            Treesize++;</span><br><span class="line">            Q.<span class="built_in">enqueue</span>(p-&gt;right);</span><br><span class="line">        &#125;</span><br><span class="line">         j++;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li>通过前序和中序建树。前序和中序确定树的顺序思想比较简单，利用前序的特性找到父节点，然后利用中序确定左右子树，然后重复这样的过程。代码如下，借鉴一下就行，看以前的代码自己都想吐槽。<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//前序和中序建树</span></span><br><span class="line"><span class="comment">//pre代表前序字符串</span></span><br><span class="line"><span class="comment">//in代表中序字符串</span></span><br><span class="line"><span class="comment">//n代表pre可以到的位置</span></span><br><span class="line"><span class="comment">//测试用例： 前序：&quot;ABHFDECKG&quot;，中序：&quot;HBDFAEKCG&quot;</span></span><br><span class="line"><span class="function">BinTreeNode *<span class="title">BinaryTree::creatBinaryTree</span><span class="params">(QString pre, QString in, <span class="keyword">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">qDebug</span>()&lt;&lt;pre;</span><br><span class="line">  <span class="built_in">qDebug</span>()&lt;&lt;in;</span><br><span class="line">  <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="keyword">int</span> k=<span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(pre[<span class="number">0</span>]!=in[k]&amp;&amp;k&lt;in.<span class="built_in">length</span>())k++;</span><br><span class="line">  <span class="keyword">if</span>(k&gt;=in.<span class="built_in">length</span>()) <span class="keyword">return</span> <span class="literal">nullptr</span>;  <span class="comment">//理论上应该需要抛出异常的，</span></span><br><span class="line">  BinTreeNode *t=<span class="keyword">new</span> <span class="built_in">BinTreeNode</span>(pre[<span class="number">0</span>]);</span><br><span class="line">  <span class="comment">//以位置k分为左子树和右子树</span></span><br><span class="line">  t-&gt;left=<span class="built_in">creatBinaryTree</span>(pre.<span class="built_in">mid</span>(<span class="number">1</span>),in,k);<span class="comment">//从0-k是左子树，所以在这里pre只能遍历到k</span></span><br><span class="line">  t-&gt;right=<span class="built_in">creatBinaryTree</span>(pre.<span class="built_in">mid</span>(k+<span class="number">1</span>),in.<span class="built_in">mid</span>(k+<span class="number">1</span>),n-k<span class="number">-1</span>);</span><br><span class="line">  <span class="comment">//由于pre和in同时都只保留右子树部分，所以pre</span></span><br><span class="line">  <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>上面建树的例子看看就行，尤其是最后一个前中序建树，也不知道自己当时是怎么写出这么魔性的代码。下面就专门介绍一下画二叉树的部分。</p><h2 id="主要画树思路"><a href="#主要画树思路" class="headerlink" title="主要画树思路"></a>主要画树思路</h2><p> 画树是利用了Qt的绘图事件，直接进行画图，画图是在建树已经完成的基础之上完成的。<strong>想法比较简单，所以画出来的比较难看，先在这里说明一下</strong>。</p><ol><li><p>二叉树的节点是圆形的，半径为25。二叉树的子节点和父节点之间x轴上相差45，y轴上100。举个例子：父节点的坐标为（x，y），则左孩子坐标为（x-45，y+100），右孩子坐标为（x+45，y+100）。根节点的坐标设置为（500，75），这些数据都可以根据自己的需求改，不定死。</p></li><li><p>数据结构设计的时候，对于二叉树的节点BinTreeNode，设计一个data（QChar类型，用于存储数据）、point（QPoint类型，用于存储位置）</p></li><li><p>数据结构设计时，对于二叉树BinaryTree，设计Mypoints（QPoint <em>类型，存储树各个结点坐标）、My_lines（ QLine </em>类型，存储需要画的线的条数）</p></li><li><p>写一个函数setMyPoints，通过层次遍历，完成各个坐标的匹配。其中对于Mypoints直接存储节点的中心，然后画圆；对于线段，从上面的例子也看得出来是父节点的中心向下半径个位置作为起点，子节点中心向上半径个位置为终点。具体代码如下所示</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//为坐标组设置应的坐标,以及得到相应的线段</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BinaryTree::setMyPoints</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">      <span class="comment">//设置父节点和子节点间横坐标相差的距离</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> i=<span class="number">0</span>;</span><br><span class="line"><span class="comment">//    int H=height();</span></span><br><span class="line">    Mypoints=<span class="keyword">new</span> QPoint[Treesize];  <span class="comment">//动态分配空间</span></span><br><span class="line">    My_lines=<span class="keyword">new</span> QLine[Treesize<span class="number">-1</span>];</span><br><span class="line"></span><br><span class="line">    QQueue&lt;BinTreeNode *&gt;Q;         <span class="comment">//调用队列</span></span><br><span class="line">    BinTreeNode *p=root;</span><br><span class="line">    root-&gt;<span class="built_in">setpoint</span>(<span class="built_in">QPoint</span>(<span class="number">500</span>,<span class="number">75</span>));  <span class="comment">//为根节点设置坐标</span></span><br><span class="line">    Q.<span class="built_in">enqueue</span>(root);</span><br><span class="line">    Mypoints[i]=root-&gt;point;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//通过层次遍历，完成各个坐标的匹配</span></span><br><span class="line">    <span class="keyword">while</span>(!Q.<span class="built_in">isEmpty</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        p=Q.<span class="built_in">dequeue</span>();</span><br><span class="line">        <span class="keyword">if</span>(p-&gt;left!=<span class="literal">nullptr</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            i++;</span><br><span class="line">            <span class="keyword">int</span> h=<span class="built_in">height</span>(p);</span><br><span class="line">            p-&gt;left-&gt;<span class="built_in">setpoint</span>(p-&gt;point-<span class="built_in">QPoint</span>(<span class="number">45</span>*h,<span class="number">-100</span>));</span><br><span class="line">            Mypoints[i]=p-&gt;left-&gt;point;</span><br><span class="line">            My_lines[i<span class="number">-1</span>].<span class="built_in">setP1</span>(p-&gt;point+<span class="built_in">QPoint</span>(<span class="number">0</span>,<span class="number">25</span>));<span class="comment">//线</span></span><br><span class="line">            My_lines[i<span class="number">-1</span>].<span class="built_in">setP2</span>(p-&gt;left-&gt;point-<span class="built_in">QPoint</span>(<span class="number">0</span>,<span class="number">25</span>));</span><br><span class="line">            Q.<span class="built_in">enqueue</span>(p-&gt;left);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(p-&gt;right!=<span class="literal">nullptr</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            i++;</span><br><span class="line">            <span class="keyword">int</span> h=<span class="built_in">height</span>(p);</span><br><span class="line">            p-&gt;right-&gt;<span class="built_in">setpoint</span>(p-&gt;point+<span class="built_in">QPoint</span>(<span class="number">45</span>*h,<span class="number">100</span>));</span><br><span class="line">            Mypoints[i]=p-&gt;right-&gt;point;</span><br><span class="line">            My_lines[i<span class="number">-1</span>].<span class="built_in">setP1</span>(p-&gt;point+<span class="built_in">QPoint</span>(<span class="number">0</span>,<span class="number">25</span>));</span><br><span class="line">            My_lines[i<span class="number">-1</span>].<span class="built_in">setP2</span>(p-&gt;right-&gt;point-<span class="built_in">QPoint</span>(<span class="number">0</span>,<span class="number">25</span>));</span><br><span class="line">            Q.<span class="built_in">enqueue</span>(p-&gt;right);</span><br><span class="line">            h--;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><ol><li>对于左侧显示的字符，这个就比较简单了，直接在建树之后进行相对应的前序、中序、后续、层次遍历，然后将字符串保存下来即可，在这里就不展开详细讲解</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我画二叉树的思想比较简单，所以画出来也不是很好看，代码虽然可以运行，但是也有一些小细节上的问题，如果有什么更好的意见欢迎指教。</p><p><a href="https://github.com/zhou-ning/Qtbinarytree.git">源码传输门</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;p&gt;Qt绘制二叉树是大二时数据结构的一个实习题目，当时的功能要求如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;键盘输入二叉树结点序列（前序或层次），创建一棵二叉树&lt;ul&gt;
&lt;li&gt;实现&lt;strong&gt;SwapTree&lt;/strong&gt;方法，以根结点为参数，交换每个结点的左子树和右子树（提示：前序递归）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;实现&lt;strong&gt;Find&lt;/strong&gt;方法，查找值为&lt;strong&gt;key&lt;/strong&gt;的结点，并输出该结点的所有祖先结点&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;输入一棵二叉树的前序遍历序列和中序遍历序列，重构这棵二叉树（这个序列里面是不带空结点’#‘的）&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="数据结构" scheme="http://example.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
    <category term="二叉树" scheme="http://example.com/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>VScode-Introduction</title>
    <link href="http://example.com/2021/05/20/VScode-Introduction/"/>
    <id>http://example.com/2021/05/20/VScode-Introduction/</id>
    <published>2021-05-20T23:13:23.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><blockquote><p>VSCode是微软推出的一款编译器，在Mac、Linux、Windows下都可以使用，听别人说挺好用，但是自己并没有尝试，现在是第一次使用，用它来写c++。<br>本篇博客主要是讲解一下VSCode写C++的配置</p><span id="more"></span><h2 id="一、VSCode下载安装"><a href="#一、VSCode下载安装" class="headerlink" title="一、VSCode下载安装"></a>一、VSCode下载安装</h2><p>VSCode下载和安装比较简单，直接百度vscode然后进入官网就能够下载(<a href="https://code.visualstudio.com/">官网传送门</a>),可以参考下图：<br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download1.png" alt=""><br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download2.png" alt=""><br>VSCode安装比较简单，就不多解释了</p></blockquote><h2 id="二、下载C-编译器"><a href="#二、下载C-编译器" class="headerlink" title="二、下载C++编译器"></a>二、下载C++编译器</h2><p>vscode只是一个简单的IDE，说白了就是一个写txt的地方，所以我们还需要下载一个编译器。我选择的编译器是MinGW(<a href="https://sourceforge.net/projects/mingw-w64/">下载传送门</a>)，下载后进行安装，安装之后直接打开会进入MinGW Installation Manaager界面，在左侧栏选择Basic Setup，然后右侧会出现7个包，我们只需要选中这七个包进行下载即可（如果有其他需求可以选择左侧的All Packages自行选择）。下载的方法是选中相对应的包然后按下鼠标右键选择“Mark For Installtion”，可以参考下图：<br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download3.png" alt=""><br>将想下载的包都选中之后，然点击菜单栏上的Installation选择Apply Changes，可以参考下图：<br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download4.png" alt=""><br>下载完成之后，C++编译器也算是完成了，最后将对应的MinGW的环境配置一下就行，简单来说就是将安装下载MinGW目录下的bin目录加到环境path当中，比如我MinGW安装的位置是：“D:\MinGW\bin”，就将“D:\MinGW\bin”加入到path当中就行，如果想测试是否安装成功，可以在cmd当中试下“g++ —version”、“gdb —version”是否都有结果如果都有则安装成功。</p><h2 id="三、在VSCode当中配置C-C-环境"><a href="#三、在VSCode当中配置C-C-环境" class="headerlink" title="三、在VSCode当中配置C/C++环境"></a>三、在VSCode当中配置C/C++环境</h2><p>配置的大部分都是参考了VSCode的官方文档，翻了许多别人写的博客，许多因为版本问题其实在现在并不是很适用，后来看了官方提供的文档，才觉得豁然开朗。在vscode当中有个文件夹.vscode比较重要，里面会存放vscode的配置文件，对于本次比较重要的配置文件有三个，分别为：tasks.json（构建指令配置）、launch.json（调试设置）、c_cpp_properties.json（编译路径路径配置）</p><h3 id="1-安装VSCode中的C-C-插件"><a href="#1-安装VSCode中的C-C-插件" class="headerlink" title="1.安装VSCode中的C/C++插件"></a>1.安装VSCode中的C/C++插件</h3><p>在Extensions（Ctrl+Shift+X）当中搜索C++进行安装,如下图：<br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download5.png" alt=""></p><h3 id="2-创建hello-cpp文件"><a href="#2-创建hello-cpp文件" class="headerlink" title="2.创建hello.cpp文件"></a>2.创建hello.cpp文件</h3><p>找一个空的目录（当作工作空间）在里面创建hello.cpp文件，然后用VSCode打开,在里面写下如下的代码：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   vector&lt;string&gt; msg &#123;<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;C++&quot;</span>, <span class="string">&quot;World&quot;</span>, <span class="string">&quot;from&quot;</span>, <span class="string">&quot;VS Code&quot;</span>, <span class="string">&quot;and the C++ extension!&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">const</span> string&amp; word : msg)</span><br><span class="line">   &#123;</span><br><span class="line">      cout &lt;&lt; word &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">   &#125;</span><br><span class="line">   cout &lt;&lt; endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>参考图如下：<br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download6.png" alt=""></p><h3 id="3-创建tasks-json文件"><a href="#3-创建tasks-json文件" class="headerlink" title="3.创建tasks.json文件"></a>3.创建tasks.json文件</h3><p>接下来，我们需要创建一个tasks.json文件来告诉VS Code如何构建（编译）程序。但是这个文件不要我们手动创建，具体可以看下面。<br>我们在主菜单中选择<strong>终端（Terminal ）&gt;配置默认生成任务（Configure Default Build Task）</strong>。在弹出来的下拉列表中，选择<strong>g++.exe build active file</strong>，点击之后他会自动生成.vscod文件夹,并且里面会自动生成tasks.json文件。<br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download7.png" alt=""><br>然后我们需要在tasks.json里面写下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="comment">// 有关 tasks.json 格式的文档，请参见</span></span><br><span class="line">    <span class="comment">// https://go.microsoft.com/fwlink/?LinkId=733558</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span>: <span class="string">&quot;2.0.0&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;tasks&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;shell&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;label&quot;</span>: <span class="string">&quot;g++.exe build active file&quot;</span>,   </span><br><span class="line">            <span class="attr">&quot;command&quot;</span>: <span class="string">&quot;D:\\MinGW\\bin\\g++.exe&quot;</span>,   <span class="comment">//对应自己下载的目录,换一下安装位置</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;-g&quot;</span>,</span><br><span class="line">                <span class="string">&quot;$&#123;file&#125;&quot;</span>,</span><br><span class="line">                <span class="string">&quot;-o&quot;</span>,</span><br><span class="line">                <span class="string">&quot;$&#123;fileDirname&#125;\\$&#123;fileBasenameNoExtension&#125;.exe&quot;</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;options&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;cwd&quot;</span>: <span class="string">&quot;D:\\MinGW\\bin&quot;</span>  <span class="comment">//对应自己下载的目录,换一下安装位置</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">&quot;problemMatcher&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;$gcc&quot;</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;group&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;kind&quot;</span>: <span class="string">&quot;build&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;isDefault&quot;</span>: <span class="literal">true</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成上诉步骤之后你就可以直接运行程序,会生成对应的exe应该可以看见（按下ctrl+shit+B可以运行）。</p><h3 id="4-创建launch-json文件"><a href="#4-创建launch-json文件" class="headerlink" title="4.创建launch.json文件"></a>4.创建launch.json文件</h3><p>目前我们并不能对代码进行调试，要想进行调试需要创建aunch.json文件，同理也不需要我们自己创建,可以选择在调试界面选择“创建launch.json文件”，或者在菜单栏中选择<strong>调试 &gt; 添加配置.</strong>，然后选择<strong>C ++（GDB / LLDB）</strong>，然后选择<strong>g++.exe build and debug active file.</strong><br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download9.png" alt=""><br>然后在launch.json文件中写下如下内容：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    </span><br><span class="line">  <span class="attr">&quot;version&quot;</span>: <span class="string">&quot;0.2.0&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;configurations&quot;</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;g++.exe build and debug active file&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;cppdbg&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;request&quot;</span>: <span class="string">&quot;launch&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;program&quot;</span>: <span class="string">&quot;$&#123;fileDirname&#125;\\$&#123;fileBasenameNoExtension&#125;.exe&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;args&quot;</span>: [],</span><br><span class="line">      <span class="attr">&quot;stopAtEntry&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">      <span class="attr">&quot;cwd&quot;</span>: <span class="string">&quot;$&#123;workspaceFolder&#125;&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;environment&quot;</span>: [],</span><br><span class="line">      <span class="attr">&quot;externalConsole&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">      <span class="attr">&quot;MIMode&quot;</span>: <span class="string">&quot;gdb&quot;</span>,</span><br><span class="line">      <span class="attr">&quot;miDebuggerPath&quot;</span>: <span class="string">&quot;D:\\MinGW\\bin\\gdb.exe&quot;</span>,      <span class="comment">//更改到自己的目录下</span></span><br><span class="line">      <span class="attr">&quot;setupCommands&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">&quot;description&quot;</span>: <span class="string">&quot;Enable pretty-printing for gdb&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;-enable-pretty-printing&quot;</span>,</span><br><span class="line">          <span class="attr">&quot;ignoreFailures&quot;</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">&quot;preLaunchTask&quot;</span>: <span class="string">&quot;g++.exe build active file&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>完成上述事情之后就可以设置断点进行相对应的调试了</p><h3 id="5-设置C-C-配置"><a href="#5-设置C-C-配置" class="headerlink" title="5.设置C/C++配置"></a>5.设置C/C++配置</h3><p>按下<strong>Ctrl+Shift+P</strong> 打开搜索界面然后选择<strong>C/C++: Edit Configurations (UI)</strong><br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download10.png" alt=""><br>选择左下角的<strong>c_cpp_properties.json 文件</strong><br><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/其他/download11.png" alt=""><br>编写c_cpp_properties.json内容如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;Win32&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;includePath&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;$&#123;workspaceFolder&#125;/**&quot;</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;defines&quot;</span>: [</span><br><span class="line">                <span class="string">&quot;_DEBUG&quot;</span>,</span><br><span class="line">                <span class="string">&quot;UNICODE&quot;</span>,</span><br><span class="line">                <span class="string">&quot;_UNICODE&quot;</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">&quot;compilerPath&quot;</span>: <span class="string">&quot;D:\\MinGW\\bin\\gcc.exe&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;cStandard&quot;</span>: <span class="string">&quot;c11&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;cppStandard&quot;</span>: <span class="string">&quot;c++17&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;intelliSenseMode&quot;</span>: <span class="string">&quot;clang-x86&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">&quot;version&quot;</span>: <span class="number">4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>可以根据自己安装路径将compilerPath的对应目录进行更换</strong></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>完成上述步骤之后，就能使用vscode进行相对应的C++编写了，不得不说vscode还是挺香的</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;VSCode是微软推出的一款编译器，在Mac、Linux、Windows下都可以使用，听别人说挺好用，但是自己并没有尝试，现在是第一次使用，用它来写c++。&lt;br&gt;本篇博客主要是讲解一下VSCode写C++的配置&lt;/p&gt;</summary>
    
    
    
    <category term="其他" scheme="http://example.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
    <category term="软件安装" scheme="http://example.com/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>android studio安装</title>
    <link href="http://example.com/2021/05/20/android%20studio%E5%AE%89%E8%A3%85/"/>
    <id>http://example.com/2021/05/20/android%20studio%E5%AE%89%E8%A3%85/</id>
    <published>2021-05-20T23:13:23.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Android-studio-下载安装"><a href="#Android-studio-下载安装" class="headerlink" title="Android studio 下载安装"></a>Android studio 下载安装</h1><h2 id="java环境配置"><a href="#java环境配置" class="headerlink" title="java环境配置"></a>java环境配置</h2><h3 id="java下载"><a href="#java下载" class="headerlink" title="java下载"></a>java下载</h3><p>去<a href="https://www.oracle.com/java/technologies/javase-downloads.html">Oracle官网</a>下载自己需要的java版本</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/企业微信截图_16104173834716.png" alt="图片"></p><p>我这里选择的是windows的jdk8</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/企业微信截图_16104172348073.png" alt="图片"></p><p>ps:下载需要登录自己Oracle账号，注册登录一下就行</p><p>下载之后的exe文件双击开，安装到你需要安装的位置即可，我这里安装位置是</p><p><code>D:\Program Files\Java\jdk1.8.0_271</code></p><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>在系统变量里面加入了变量<code>JAVA_HOME</code>，值为安装的位置</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/image-20210113195035403.png" alt=""></p><p>然后在Path里面加入了<code>%JAVA_HOME%\bin</code>和<code>%JAVA_HOME%\jre\bin</code>(这个有待商量)</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/image-20210113195354124.png" alt=""></p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>在cmd当中输入<code>java -version</code>和<code>javac -version</code>查看输出，如果有如下的输出说明配置正确</p><p><code>java -version</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java version &quot;1.8.0_271&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_271-b09)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.271-b09, mixed mode)</span><br></pre></td></tr></table></figure><p><code>javac -version</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">javac 1.8.0_271</span><br></pre></td></tr></table></figure><h2 id="Android-studio下载和安装"><a href="#Android-studio下载和安装" class="headerlink" title="Android studio下载和安装"></a>Android studio下载和安装</h2><h3 id="android-studio下载"><a href="#android-studio下载" class="headerlink" title="android studio下载"></a>android studio下载</h3><p>直接去<a href="https://developer.android.com/studio?hl=zh-cn">官网</a>,下载<code>installer.exe</code>或者zip都可以，我这里是下载的zip。</p><p>然后找个合适的位置解压，解压完之后是这个样子</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/image-20210114095707274.png" alt=""></p><p>我们进入bin文件点击<code>studio64.exe</code>就可以运行</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/image-20210114095925560.png" alt=""></p><h3 id="第一次运行"><a href="#第一次运行" class="headerlink" title="第一次运行"></a>第一次运行</h3><p>第一次运行可能会下载一些sdk等东西，这里的话只需要记得更改sdk下载位置，别下载到c盘就行。</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/企业微信截图_16105903698073.png" alt=""></p><p>ps:网络可能会导致很难下载下来，这个可以通过设置镜像等方法解决</p><h2 id="Android环境配置"><a href="#Android环境配置" class="headerlink" title="Android环境配置"></a>Android环境配置</h2><p>Android 环境配置主要配置sdk的环境变量，跟上面java环境配置类似，在系统变量中加入<code>ANDROID_HOME</code>对应着sdk安装位置</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/企业微信截图_16106158683453.png" alt=""></p><p>然后在path当中加入<code>%ANDROID_HOME%\platform-tools</code>和<code>%ANDROID_HOME%\tools</code></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/image-20210114172309012.png" alt=""></p><h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><p>在cmd当中输入adb，然后输出类似如下信息</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Android Debug Bridge version 1.0.41</span><br><span class="line">Version 30.0.5-6877874</span><br><span class="line">Installed as D:\Users\ningzzhou\AppData\Local\Android\SDK\platform-tools\adb.exe</span><br><span class="line"></span><br><span class="line">global options:</span><br><span class="line"> -a         listen on all network interfaces, not just localhost</span><br><span class="line"> -d         use USB device (error if multiple devices connected)</span><br></pre></td></tr></table></figure><p>更多环境变量配置可以参考官网：<a href="https://developer.android.com/studio/command-line/variables?hl=zh-cn">https://developer.android.com/studio/command-line/variables?hl=zh-cn</a></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Android studio因为经常需要安装,所以记录一下</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Android-studio-下载安装&quot;&gt;&lt;a href=&quot;#Android-studio-下载安装&quot; class=&quot;headerlink&quot; title=&quot;Android studio 下载安装&quot;&gt;&lt;/a&gt;Android studio 下载安装&lt;/h1&gt;&lt;h2 id=&quot;java环境配置&quot;&gt;&lt;a href=&quot;#java环境配置&quot; class=&quot;headerlink&quot; title=&quot;java环境配置&quot;&gt;&lt;/a&gt;java环境配置&lt;/h2&gt;&lt;h3 id=&quot;java下载&quot;&gt;&lt;a href=&quot;#java下载&quot; class=&quot;headerlink&quot; title=&quot;java下载&quot;&gt;&lt;/a&gt;java下载&lt;/h3&gt;&lt;p&gt;去&lt;a href=&quot;https://www.oracle.com/java/technologies/javase-downloads.html&quot;&gt;Oracle官网&lt;/a&gt;下载自己需要的java版本&lt;/p&gt;</summary>
    
    
    
    <category term="android" scheme="http://example.com/categories/android/"/>
    
    
    <category term="软件安装" scheme="http://example.com/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>eclipse中android环境配置</title>
    <link href="http://example.com/2021/05/20/eclipse%E4%B8%ADandroid%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2021/05/20/eclipse%E4%B8%ADandroid%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</id>
    <published>2021-05-20T23:13:23.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h1 id="eclipse中android环境配置"><a href="#eclipse中android环境配置" class="headerlink" title="eclipse中android环境配置"></a>eclipse中android环境配置</h1><h2 id="java环境配置"><a href="#java环境配置" class="headerlink" title="java环境配置"></a>java环境配置</h2><h3 id="java下载"><a href="#java下载" class="headerlink" title="java下载"></a>java下载</h3><p>去<a href="https://www.oracle.com/java/technologies/javase-downloads.html">Oracle官网</a>下载自己需要的java版本</p><span id="more"></span><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/企业微信截图_16104173834716.png" alt="图片"></p><p>我这里选择的是windows的jdk8</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/企业微信截图_16104172348073.png" alt="图片"></p><p>ps:下载需要登录自己Oracle账号，注册登录一下就行</p><p>下载之后的exe文件双击开，安装到你需要安装的位置即可，我这里安装位置是</p><p><code>D:\Program Files\Java\jdk1.8.0_271</code></p><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>在系统变量里面加入了变量<code>JAVA_HOME</code>，值为安装的位置</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/image-20210113195035403.png" alt=""></p><p>然后在Path里面加入了<code>%JAVA_HOME%\bin</code>和<code>%JAVA_HOME%\jre\bin</code>(这个有待商量)</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/android/image-20210113195354124.png" alt=""></p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>在cmd当中输入<code>java -version</code>和<code>javac -version</code>查看输出，如果有如下的输出说明配置正确</p><p><code>java -version</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java version &quot;1.8.0_271&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_271-b09)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.271-b09, mixed mode)</span><br></pre></td></tr></table></figure><p><code>javac -version</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">javac 1.8.0_271</span><br></pre></td></tr></table></figure><h2 id="eclipse下载和配置"><a href="#eclipse下载和配置" class="headerlink" title="eclipse下载和配置"></a>eclipse下载和配置</h2><h3 id="eclipse下载"><a href="#eclipse下载" class="headerlink" title="eclipse下载"></a>eclipse下载</h3><p>去<a href="https://www.eclipse.org/downloads/packages/">官网</a>下载Eclipse IDE for Enterprise Java Developers</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/企业微信截图_16107116328073-1610711653956.png" alt=""></p><p>ps:下载的时候可能要你捐款什么的，跳过即可</p><p>解压完之后是这样的</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/企业微信截图_16111073888073.png" alt=""></p><p>点击eclipse.exe就能够运行</p><h3 id="下载adt"><a href="#下载adt" class="headerlink" title="下载adt"></a>下载adt</h3><p>adt是eclipse里面的Android插件，有这个才能在eclipse里面开发Android</p><p>点击<code>Help-&gt;Install New Software</code>,进入安装插件的界面</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/image-20210120095351409.png" alt=""></p><p>点击<code>Add</code>添加插件地址</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/企业微信截图_16111078194716.png" alt=""></p><p>插件我设置名字为<code>ADT</code>,地址为<code>http://dl-ssl.google.com/android/eclipse</code></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/image-20210120095943961.png" alt=""></p><p>之后只需要按照安装正常插件的过程一样安装一下就行</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/image-20210120100225418.png" alt=""></p><p>ps：我已经安装了，所以显示都安装了</p><p>安装后可以在<code>About Eclipse IDE</code>上看到</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/image-20210120163100705.png" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/image-20210120163135222.png" alt=""></p><h2 id="SDK以及工具下载"><a href="#SDK以及工具下载" class="headerlink" title="SDK以及工具下载"></a>SDK以及工具下载</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>我们需要先下载SDK Manager等工具下载sdk，工具下载地址：<a href="https://dl.google.com/android/android-sdk_r24.4.1-windows.zip?utm_source=androiddevtools&amp;utm_medium=website。">https://dl.google.com/android/android-sdk_r24.4.1-windows.zip?utm_source=androiddevtools&amp;utm_medium=website。</a></p><p>下载解压之后是这样的</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/image-20210120164312559.png" alt=""></p><p>双击SDK Manager.exe，对sdk以及相对应的工具进行下载。</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/image-20210120164715178.png" alt=""></p><p>下载完成后我这边多了许多东西</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/image-20210120164747825.png" alt=""></p><p>ps：网络可能不好，需要换源</p><p>需要注意在SDK manager中下载的android SDK Build-tools工具，因为adt不再升级，所以android SDK Build-tools版本不能太高，推荐为24</p><h3 id="eclipse上配置"><a href="#eclipse上配置" class="headerlink" title="eclipse上配置"></a>eclipse上配置</h3><p>在Preferences-&gt;Android当中配置一下SDK的位置，浏览选择到我们解压zip的位置就行</p><p><img src="https://cdn.jsdelivr.net/gh/zhou-ning/blog-image-bed@main/eclipse/企业微信截图_16111325677086.png" alt=""></p><p>ps：SDK用Android Studio其实也可以进行下载，但是不知道为啥eclipse使用不了，可能是不太兼容吧，毕竟adt都不维护了</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>使用eclipse来编写Android已经过时了，但是有时候我们需要维护以前用eclipse写的代码，所以迫于无奈还是得使用eclipse。所以记一下环境配置，方便后续的维护</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;eclipse中android环境配置&quot;&gt;&lt;a href=&quot;#eclipse中android环境配置&quot; class=&quot;headerlink&quot; title=&quot;eclipse中android环境配置&quot;&gt;&lt;/a&gt;eclipse中android环境配置&lt;/h1&gt;&lt;h2 id=&quot;java环境配置&quot;&gt;&lt;a href=&quot;#java环境配置&quot; class=&quot;headerlink&quot; title=&quot;java环境配置&quot;&gt;&lt;/a&gt;java环境配置&lt;/h2&gt;&lt;h3 id=&quot;java下载&quot;&gt;&lt;a href=&quot;#java下载&quot; class=&quot;headerlink&quot; title=&quot;java下载&quot;&gt;&lt;/a&gt;java下载&lt;/h3&gt;&lt;p&gt;去&lt;a href=&quot;https://www.oracle.com/java/technologies/javase-downloads.html&quot;&gt;Oracle官网&lt;/a&gt;下载自己需要的java版本&lt;/p&gt;</summary>
    
    
    
    <category term="android" scheme="http://example.com/categories/android/"/>
    
    
    <category term="软件安装" scheme="http://example.com/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>神经网络</title>
    <link href="http://example.com/2021/05/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://example.com/2021/05/20/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</id>
    <published>2021-05-20T23:13:23.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><blockquote><p>在机器学习的基础知识学习过程当中，学习了一下神经网络，然后就机器学习方面的神经网络和卷积神经网络方面写一下自己的个人理解，顺便总结一下。</p></blockquote><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="一、神经元模型"><a href="#一、神经元模型" class="headerlink" title="一、神经元模型"></a>一、神经元模型</h3><p>神经元是神经网络当中最基本的模型。在生物神经网络中每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变其他神经元内的电位;如果这些神经元的电位超过了 个“阔值” ，那么它就会被激活 “兴奋“起来，也同样会向其他神经元发送化学物质。<br><span id="more"></span><br>​    在机器学习当中，人们将这个模型抽象出来，就产生了机器学习当中的<strong>神经元模型</strong>，如下图，$x<em>i$就是其他神经元的输入（相当于神经物质），$\omega_i$为权值，神经网络主要学习的就是这个权值，$ \theta $为对应的阈值，超过这个阈值就向其他神经元发送化学物质，而这个$f$是激活函数，用于判断是否发送化学物质，产生的值为0或者1（0不发送，1就发送）,$f$可以理解为输入$\sum</em>{i=1}^{n}\omega_ix_i-\theta$输出0或者1的函数。</p><p>​    所有一个神经元的输入为$x_i$,输出为0或者1（个人认为可以简单这样理解），计算公式如下：</p><script type="math/tex; mode=display">y=f(\sum_{i=1}^{n}\omega_ix_i-\theta)</script><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络1.png" alt="神经网络1" style="zoom:80%;" /></p><p><strong>相关趣事</strong>：</p><blockquote><p>1943年，心理学家McCulloch和数学家Pitts参考了生物神经元的结构，发表了抽象的神经元模型MP，1943年发布的MP模型，虽然简单，但已经建立了神经网络大厦的地基。但是，MP模型中，权重的值都是预先设置的，因此不能学习。1949年心理学家Hebb提出了Hebb学习率，认为人脑神经细胞的突触（也就是连接）上的强度上可以变化的。于是计算科学家们开始考虑用调整权值的方法来让机器学习。这为后面的学习算法奠定了基础。</p></blockquote><h3 id="二、激活函数"><a href="#二、激活函数" class="headerlink" title="二、激活函数"></a>二、激活函数</h3><pre><code>     神经元最终是通过激活函数的处理产生神经元的输出,最开始的时候激活函数的模型为$sgn(x)$(如下图a，其实在数学课上见过很多次这个函数)，刚好符合我们的要求，当$(\sum_&#123;i=1&#125;^&#123;n&#125;\omega_ix_i-\theta)&gt;0$时，输出1否则输出0。可是这个函数的缺点是不可导，这在数学上性质就很不好，所以人们就用另外一个性质优秀的函数代替了它，就是$sigmoid(x)$函数（如下图b，记住这个函数后面会用到）。</code></pre><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络2.png" alt="神经网络2" style="zoom:80%;" /></p><p>​        除了这两个函数之外，还有许多其他的常用的激活函数，如：$tanh:f(x)=tanh(x)、ReLU：f(x)=max(x,0)、softmax:f(x)=log(1+exp(x))$</p><h3 id="三、感知机"><a href="#三、感知机" class="headerlink" title="三、感知机"></a>三、感知机</h3><p>​        由于一个神经元的功能太过鸡肋，所以在1958年，计算科学家Rosenblatt提出了提出了两层神经元组成的神经网络，取名为“感知机”。</p><p>​        感知机由两层神经元组成，输入层接收外界输入信息后传给输出层，输出层是M-P神经元。感知器是当时首个可以学习的人工神经网络，当时Rosenblatt现场演示了其学习识别简单图像的过程，在当时的社会引起了轰动。</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络3.png" alt="神经网络3" style="zoom:80%;" /></p><p>​        感知机可以解决线性问题，如：</p><ol><li>“与”问题($x_1$^$x_2$)，令参数$\omega_1=1,\omega_2=1,\theta=2$,则有$y=f(1<em>x_1+1</em>x_2-2)$,当且仅当$x_1=x_2=1$时，才有$y=1$</li><li>“或”问题($x_1$||$x_2$)，令参数$\omega_1=1,\omega_2=1,\theta=0.5$,则有$y=f(1<em>x_1+1</em>x_2-0.5)$,当且仅当$x_1=1或者x_2=1$时，有$y=1$</li><li>“非问题”(~$x_1$)，令参数$\omega_1=-0.6,\omega_2=0,\theta=-0.5$,则有$y=f(-0.6<em>x_1+0</em>x_2+0.5)$,当$x_1=1,y=0$;当$x_1=0,y=1$</li></ol><p>感知机可以解决线性问题，可以这也理解，看下图</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络4.png" alt="神经网络4" style="zoom: 80%;" /></p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络5.png" alt="神经网络5" style="zoom:80%;" /></p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络6.png" alt="神经网络6" style="zoom:80%;" /></p><p>可以发现$z=g(\omega_{i,j}*a_i)$,是以矩阵形式呈现的，和机器学习前面学的线性模型的表达式一样，所以感知机其实可以认为是一个线性模型。</p><p><strong>相关历史趣事</strong>：</p><blockquote><p>​        1958年，计算科学家Rosenblatt提出了由两层神经元组成的神经网络。他给它起了一个名字:“感知器”（Perceptron）（有的文献翻译成“感知机”）。</p><p>感知器是当时首个可以学习的人工神经网络。Rosenblatt现场演示了其学习识别简单图像的过程，在当时的社会引起了轰动。人们认为已经发现了智能的奥秘，许多学者和科研机构纷纷投入到神经网络的研究中。美国军方大力资助了神经网络的研究，并认为神经网络比“原子弹工程”更重要。这段时间直到1969年才结束，这个时期可以看作神经网络的第一次高潮。</p><p>​        但是，Minsky在1969年出版了一本叫《Perceptron》的书，里面用详细的数学证明了感知器的弱点，尤其是感知器对XOR（异或）这样的简单分类任务都无法解决。由于Minsky的巨大影响力以及书中呈现的悲观态度，让很多学者和实验室纷纷放弃了神经网络的研究。神经网络的研究陷入了冰河期。这个时期又被称为“AI winter”。接近10年以后，对于两层神经网络的研究才带来神经网络的复苏。</p></blockquote><h3 id="四、多层神经网络和BP算法"><a href="#四、多层神经网络和BP算法" class="headerlink" title="四、多层神经网络和BP算法"></a>四、多层神经网络和BP算法</h3><h4 id="1-多层神经网络"><a href="#1-多层神经网络" class="headerlink" title="1.多层神经网络"></a>1.多层神经网络</h4><p>​        由于感知机对非线性问题的乏力，为了解决非线性问题，就提出了多层神经网络。多层神经网络：输入层和输出层之间加一层神经元（隐含层），隐含层和输出层神经元都拥有激活函数的功能神经元，并且有理论证明，两层神经网络可以无限逼近任意连续函数。</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络7.png" alt="神经网络7" style="zoom:80%;" /></p><p>​        出现多层神经网络的原因是误差逆传播算法的出现。误差传播算法（error BackPropagation,简称BP）算法，被成为迄今为止最成功的神经网络算法，在现实任务中使用神经网络时，大多数时在使用BP算法进行训练。</p><h4 id="2-BP算法"><a href="#2-BP算法" class="headerlink" title="2.BP算法"></a>2.BP算法</h4><p>给定训练集$D=\left{(x_1,y_1),(x_2,y_2),…,(x_m,y_m)\right},x_i\in R^d,y_i\in R^d$</p><p>假设一个神经网络有$d$个输入神经元、$l$个输出神经元，$q$个隐含神经元(可以参考下图)</p><p>设输出层第$j$个神经元的阈值用$\theta_i$表示，隐含层第$h$个神经元阈值用$\gamma_h$表示</p><p>输入层第$i$个神经元和隐含层第$h$个神经元之间权重为$\upsilon<em>{ih}$;隐含层第$h$个神经元和输出层第$j$个神经元之间权重为$\omega</em>{hj}$</p><p>记隐含层第$h$个神经元的输入为$\alpha<em>h=\sum</em>{i=1}^{d}{\upsilon<em>{ih}x_i}$;输出层第$j$个神经元接收的输入为$\beta_j=\sum</em>{h=1}^{q}{\omega_{hj}b_h}$（其中$b_h$为隐含层第$h$个神经元的输出）</p><p>然后假设隐藏层和输出层都使用$sigmoid(x)$函数作为激活函数，因为该函数有可导的性质，该函数的导数为$f\prime(x)=f(x)(1-f(x))$</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络8.png" alt="神经网络8" style="zoom:80%;" /></p><p>对于其中的训练例子$(x_k,y_k)$,假设神经网络的输出为$\hat y_k=(\hat y_1^k,\hat y_2^k,…,\hat y_l^k)$,即$\hat y_l^k=f(\beta_j-\theta_j)$</p><p>可以得到均方误差$E_k=\frac{1}{2}(\hat y^k_j-y^k_j)^2$,并且有$(d+l+1)*q+l$个参数需要确定。</p><p>以其中权重参数$\omega<em>{hj}$为例，它的更新估计式：$\omega\leftarrow\omega+\Delta\omega$,其中$\Delta\omega=-\eta\frac{ \partial E_k}{\partial \omega</em>{hj}}$（就是求偏导，其中$\eta$为学习率）</p><p>式子：$\frac{ \partial E<em>k}{\partial \omega</em>{hj}}=\frac{\partial E<em>k}{\partial \hat y^k_j}\cdot\frac{\partial \hat y^k_j}{\partial \beta_j}\cdot\frac{\partial \beta_j}{\partial \omega</em>{hj}}$</p><p>可以知道$\frac{\partial \beta<em>j}{\partial  \omega</em>{hj}}=b_h$,然后设</p><script type="math/tex; mode=display">g_i=\frac{\partial E_k}{\partial  \hat y^k_j}\cdot\frac{\partial  \hat y^k_j}{\partial  \beta_j}</script><p>由于$E_k=\frac{1}{2}(\hat y^k_j-y^k_j)^2$以及$\hat y_l^k=f(\beta_j-\theta_j)$，所以有</p><script type="math/tex; mode=display">g_i=(\hat y^k_j-y^k_j)\cdot f\prime(\beta_j-\theta_j)</script><p>再由激活函数$f(x)$为$sigmoid(x)$函数，所以导数$f\prime(x)=f(x)(1-f(x))$，则：</p><script type="math/tex; mode=display">g_i=\hat y^k_j(1-\hat y^k_j)(y^k_j-\hat y^k_j)</script><p>这样我们就得到了</p><script type="math/tex; mode=display">\Delta\omega=\eta g_ib_h</script><p>同理我们可以得到其他的参数值，如：$\Delta \theta<em>j=-\eta g_i$、$\Delta \upsilon</em>{ih}=\eta e<em>h x_i$、$\Delta \gamma_h=-\eta e_h$,其中$e_h=b_h(1-b_h)\sum</em>{j=1}^{l}{\omega_{hj}gi}$</p><p>上面只是简单的说明了一下在神经网络过程中，参数大概是怎么计算出来的，在正真的编程的时候其实这些过程都不需要我们自己实现，一般的深度学习框架都帮我们实现了。</p><h4 id="3-过拟合问题"><a href="#3-过拟合问题" class="headerlink" title="3.过拟合问题"></a>3.过拟合问题</h4><p>由于神经网络强大的表示能力，经常会出现过拟合问题，一般解决方法由两种：</p><ul><li><p>“早停”：将数据分为训练集和验证集，训练集计算梯度、更新权值和阈值，验证集用来估计误差</p></li><li><p>“正则化”：其思想是在误差目标函数中增加一个用于描述网路复炸程度的部分，例如连接权值和阈值的平方和，如下图，其中λϵ（0，1），用于对经验误差与网络复杂度进行折中。</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络9.png" alt="神经网络9" style="zoom: 50%;" /></p></li></ul><p><strong>相关历史趣事：</strong></p><blockquote><p>​        1986年，Rumelhar和Hinton等人提出了反向传播（Backpropagation，BP）算法，解决了两层神经网络所需要的复杂计算量问题，从而带动了业界使用两层神经网络研究的热潮。但是不幸的是，当时的神经网络任然存在很多问题，比如训练时间长、优化困难等。值得注意的是这个时候的Hinton还比较年轻，30年以后，正是他重新定义了神经网络，带来了神经网络复苏的又一春。</p><p>​        90年代中期，由Vapnik等人发明的SVM（Support Vector Machines，支持向量机）算法诞生，很快就在若干个方面体现出了对比神经网络的优势：无需调参；高效；全局最优解。基于以上种种理由，SVM迅速打败了神经网络算法成为主流，神经网络的研究再次陷入了冰河期。</p><p>​        直到2006年，Hinton在《Science》和相关期刊上发表了论文，首次提出了“深度信念网络”的概念，同时他给多层神经网络相关的学习方法赋予了一个新名词—“<strong>深度学习</strong>”，就在这之后，关于深度神经网络的研究与应用不断涌现。</p><p>​        2019年3月27日 ——ACM宣布，深度学习的三位创造者Yoshua Bengio， Yann LeCun， 以及Geoffrey Hinton获得了2019年的图灵奖。</p></blockquote><p>Hinton老爷子的照片：</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/机器学习/神经网络10.png" alt="神经网络10"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>简单的讲解了一下神经网络的基本概念，并没有涉及CNN、RNN等相关的东西。然后自己用pytorch写了一下这个神经网络识别手写数据集：<a href="https://github.com/Zhounning/MachineLearning/blob/master/arithmetic/MNIST手写数字数据集MLP.ipynb">点这里</a></p><p><strong>参考</strong>：</p><p>《机器学习》—周志华</p><p><a href="https://www.cnblogs.com/subconscious/p/5058741.html">https://www.cnblogs.com/subconscious/p/5058741.html</a></p><p><a href="https://www.zhihu.com/question/22553761">https://www.zhihu.com/question/22553761</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;在机器学习的基础知识学习过程当中，学习了一下神经网络，然后就机器学习方面的神经网络和卷积神经网络方面写一下自己的个人理解，顺便总结一下。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;神经网络&quot;&gt;&lt;a href=&quot;#神经网络&quot; class=&quot;headerlink&quot; title=&quot;神经网络&quot;&gt;&lt;/a&gt;神经网络&lt;/h2&gt;&lt;h3 id=&quot;一、神经元模型&quot;&gt;&lt;a href=&quot;#一、神经元模型&quot; class=&quot;headerlink&quot; title=&quot;一、神经元模型&quot;&gt;&lt;/a&gt;一、神经元模型&lt;/h3&gt;&lt;p&gt;神经元是神经网络当中最基本的模型。在生物神经网络中每个神经元与其他神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变其他神经元内的电位;如果这些神经元的电位超过了 个“阔值” ，那么它就会被激活 “兴奋“起来，也同样会向其他神经元发送化学物质。&lt;br&gt;</summary>
    
    
    
    <category term="机器学习" scheme="http://example.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="深度学习" scheme="http://example.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="神经网络" scheme="http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>第15讲：SCRUM敏捷软件模型开发过程</title>
    <link href="http://example.com/2021/05/20/%E7%AC%AC15%E8%AE%B2%EF%BC%9ASCRUM%E6%95%8F%E6%8D%B7%E8%BD%AF%E4%BB%B6%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B/"/>
    <id>http://example.com/2021/05/20/%E7%AC%AC15%E8%AE%B2%EF%BC%9ASCRUM%E6%95%8F%E6%8D%B7%E8%BD%AF%E4%BB%B6%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B/</id>
    <published>2021-05-20T23:13:23.000Z</published>
    <updated>2021-06-15T14:52:08.778Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>重点：</p><p>（1）回顾和思考CMMI模型的核心思想是什么？这一模型有什么特点？适合什么样的企业和项目？<br>（2）了解学界所说的“重”过程的“重”是什么意思？ 与之相对应的“轻”过程的轻又是什么意思？<br>（3）了解敏捷软件开发过程的指导思想，了解SCRUM的基本框架。<br>（4）理解SCRUM敏捷开发模型的”三个角色“、”三个工件“、”四</p><p>个会议“的内容和方法。</p></blockquote><span id="more"></span><h2 id="一、简介："><a href="#一、简介：" class="headerlink" title="一、简介："></a>一、简介：</h2><p>思想：一切为了简单、快捷</p><p>简介：</p><p>Scrum：一种迭代开发框架，是一个轻量级的项目管理的框架。它的核心在于迭代。</p><ol><li>三个角色：产品经理、项目经理、开发团队</li><li>三个工件：产品订单、冲刺订单、燃尽图</li><li>四个会议：每日站立会、冲刺计划会、冲刺评审会、冲刺回顾会</li></ol><p>Scrum包括：1)预定义的角色；2)实践活动；3) 文档</p><p>Scrum角色：</p><ul><li>Scrum Master</li><li>产品负责人</li><li>开发团队</li></ul><p>Scrum 实践活动：</p><ul><li>冲刺：2到6周</li><li>冲刺计划会：确定做什么</li><li>站立会议：及时反馈</li></ul><h2 id="二、相关概念"><a href="#二、相关概念" class="headerlink" title="二、相关概念"></a>二、相关概念</h2><div class="table-container"><table><thead><tr><th>名词</th><th>解释</th></tr></thead><tbody><tr><td>Sprint</td><td>冲刺周期，一般为2到6周时间</td></tr><tr><td>Sprint Planning Meeting</td><td>冲刺计划会</td></tr><tr><td>Sprint summary</td><td>冲刺回顾会</td></tr><tr><td>User Story</td><td>用户的外在业务需求，如查询余额。也就是小目标</td></tr><tr><td>Task</td><td>由User Story拆分成的具体开发任务</td></tr><tr><td>Backlog</td><td>需求列表，可以看成小目标的清单。分为<strong>Sprint Backlog</strong>和<strong>Product Backlog</strong></td></tr><tr><td>Product Backlog</td><td>产品 订单</td></tr><tr><td>Sprint Backlog</td><td>冲刺订单</td></tr><tr><td>Daily meeting</td><td>每天的站会，用于监控项目进度</td></tr><tr><td>Sprint Review meeting</td><td>冲刺评审会议，让团队成员演示成果</td></tr><tr><td>Sprint burn down</td><td>冲刺燃尽图，说白了就是记录当前周期的需求完成情况</td></tr><tr><td>Rlease</td><td>开发周期完成，项目发布新的可用版本</td></tr></tbody></table></div><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/敏捷开发/敏捷开发1.png" alt="敏捷开发1"></p><h2 id="三、Scrum-Team"><a href="#三、Scrum-Team" class="headerlink" title="三、Scrum Team"></a>三、Scrum Team</h2><p>Scrum团队由所有对最终发布的产品做出贡献的人组成</p><p>“SCRUM Master”角色：相当于项目经理,维护过程和任务</p><p>团队包括：</p><ul><li>Scrum主管(Scrum Master)</li><li>产品负责人(Product Owner)，代表利益所有者</li><li>开发人员 (Developer)</li><li>测试人员(Tester)</li><li>文档工程师(Documentation Member)</li><li>……</li></ul><p>其中开发人员、测试人员、文档工程师属于开发团队。经典团队拥有5~9人，团队成员有较好的自我组织和管理。</p><h3 id="1-Scrum主管"><a href="#1-Scrum主管" class="headerlink" title="1.Scrum主管"></a>1.Scrum主管</h3><p>Scrum主管在实际项目中称为项目经理，主要工作：去除那些影响团队交付冲刺目标的障碍。Scrum主管并非团队的领导（由于他们是自我组织的），而是负责屏蔽外界对开发团队的干扰。Scrum主管确保Scrum过程按照初衷使用。Scrum主管是规则的执行者。</p><h3 id="2-产品负责人"><a href="#2-产品负责人" class="headerlink" title="2.产品负责人"></a>2.产品负责人</h3><p>产品负责人又称产品经理，代表客户的意愿，保证Scrum团队在做从业务角度来说正确的事情。</p><p>产品负责人的工作：</p><ul><li>编写用户故事</li><li>排出优先级</li><li>形成产品订单</li></ul><h3 id="3-开发团队"><a href="#3-开发团队" class="headerlink" title="3.开发团队"></a>3.开发团队</h3><p>开发团队是负责开发并交付产品的团队。团队规模要小，组成大致为5至9名具有跨职能技能的人（设计者，开发者等）,实践中，2~9人均可，但超过7人会导致沟通成本上升，最好团队成员技能水平大致相同。</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/敏捷开发/敏捷开发2.png" alt="敏捷开发2"></p><h3 id="4-参与者"><a href="#4-参与者" class="headerlink" title="4.参与者"></a>4.参与者</h3><p>参与者包括用户和利益相关者，他们并不是实际Scrum过程的一部分，但是必须考虑他们。利益所有者（客户，提供商）是影响项目成功的人，但只直接参与冲刺评审过程。</p><h2 id="四、Scrum-活动"><a href="#四、Scrum-活动" class="headerlink" title="四、Scrum 活动"></a>四、Scrum 活动</h2><h3 id="1-Sprints"><a href="#1-Sprints" class="headerlink" title="1.Sprints"></a>1.Sprints</h3><p>Scrum项目周期以一组迭代周期“sprints”组成。典型的迭代周期为2~4周或者最多一个自然月，产品的设计、开发、测试全部都在一个迭代内完成。</p><h3 id="2-Sprint-Planning-Meeting-（冲刺计划会）"><a href="#2-Sprint-Planning-Meeting-（冲刺计划会）" class="headerlink" title="2.Sprint Planning Meeting （冲刺计划会）"></a>2.Sprint Planning Meeting （冲刺计划会）</h3><p>冲刺计划会主要是确定冲刺目标，简单程数这个迭代将要完成什么</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/敏捷开发/敏捷开发3.png" alt="敏捷开发3" style="zoom:80%;" /></p><h3 id="3-Daily-Stand-Meeting"><a href="#3-Daily-Stand-Meeting" class="headerlink" title="3.Daily Stand Meeting"></a>3.Daily Stand Meeting</h3><p>每天站立会议是一个每天都会开的，时间为15分钟左右的会议，特点是所有人都站着开会。其中所有相关的人都会被邀请，但是只有Scrum master，Product Owner，团队成员能够在会上发言，这样避免了无关的讨论，可以提高效率。</p><p>其中团队成员需要回答3个问题：</p><ul><li>昨天你做了什么</li><li>今天你将要做什么</li><li>你有需要帮助的地方吗</li></ul><h3 id="4-冲刺评审会"><a href="#4-冲刺评审会" class="headerlink" title="4.冲刺评审会"></a>4.冲刺评审会</h3><p>在冲刺评审会上，团队需要演示所完成的迭代工作，典型的做法是使用演示形式展示新功能或者底层架构实现，整个团队和关注产品的人都要需要参加。</p><h3 id="5-冲刺回顾会"><a href="#5-冲刺回顾会" class="headerlink" title="5.冲刺回顾会"></a>5.冲刺回顾会</h3><p>周期性 回顾，总结工作中的禁言和教训，时间大概为15到30分钟左右。在每个迭代结束时开始做，整个团队都需要参加，包括客户也可能需要参加。</p><h2 id="五、Scrum-的文档-工件"><a href="#五、Scrum-的文档-工件" class="headerlink" title="五、Scrum 的文档 (工件)"></a>五、<strong>Scrum</strong> <strong>的文档</strong> (工件)</h2><h3 id="1-product-backlog-（产品订单"><a href="#1-product-backlog-（产品订单" class="headerlink" title="1.product backlog （产品订单)"></a>1.product backlog （产品订单)</h3><p>产品订单写的是项目中待完成的工作列表，理想的是每一个待完成的工作都将对客户和用户产生价值，产品所有者将对这个列表进行优先级排序，每个迭代开始前优先级的排序工作还需要再度修正。</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/敏捷开发/敏捷开发4.png" alt="敏捷开发4" style="zoom:80%;" /></p><h3 id="2-Sprint-backlog-冲刺订单"><a href="#2-Sprint-backlog-冲刺订单" class="headerlink" title="2.Sprint backlog (冲刺订单)"></a>2.Sprint backlog (冲刺订单)</h3><p>Sprint Backlog是Product Backlog的子集，Sprint Backlog的内容，由团队成员集体决定，团队中任何人都可以添加，删减或者更改迭代中的工作项目，团队中的每个人都为了冲刺目标以及将发布的结果而工作。</p><p><img src="https://gitee.com/zhou-ning/BlogImage/raw/master/敏捷开发/敏捷开发5.png" alt="敏捷开发5" style="zoom:80%;" /></p><h2 id="六、Scrum过程"><a href="#六、Scrum过程" class="headerlink" title="六、Scrum过程"></a>六、Scrum过程</h2><p>待续……</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>敏捷的最佳实践之一就是迭代开发，敏捷/迭代开发的核心思想是：聚集客户价值，以客户为中心，交付刚刚好的系统，随时构建产品质量。</p>]]></content>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;重点：&lt;/p&gt;
&lt;p&gt;（1）回顾和思考CMMI模型的核心思想是什么？这一模型有什么特点？适合什么样的企业和项目？&lt;br&gt;（2）了解学界所说的“重”过程的“重”是什么意思？ 与之相对应的“轻”过程的轻又是什么意思？&lt;br&gt;（3）了解敏捷软件开发过程的指导思想，了解SCRUM的基本框架。&lt;br&gt;（4）理解SCRUM敏捷开发模型的”三个角色“、”三个工件“、”四&lt;/p&gt;
&lt;p&gt;个会议“的内容和方法。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="其他" scheme="http://example.com/categories/%E5%85%B6%E4%BB%96/"/>
    
    
    <category term="敏捷开发" scheme="http://example.com/tags/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
</feed>
